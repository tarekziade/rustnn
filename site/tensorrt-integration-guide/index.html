
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Python bindings for the W3C WebNN API">
      
      
        <meta name="author" content="Your Organization">
      
      
        <link rel="canonical" href="https://your-org.github.io/rustnn/tensorrt-integration-guide/">
      
      
      
      
        
      
      
      <link rel="icon" href="../logo/rustnn.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.7.0">
    
    
      
        <title>TensorRT Integration Guide - WebNN Python API</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.618322db.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.ab4e12ef.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#tensorrt-integration-guide" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="WebNN Python API" class="md-header__button md-logo" aria-label="WebNN Python API" data-md-component="logo">
      
  <img src="../logo/rustnn.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            WebNN Python API
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              TensorRT Integration Guide
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/your-org/rustnn" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    your-org/rustnn
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href=".." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../getting-started/" class="md-tabs__link">
        
  
  
    
  
  Getting Started

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../api-reference/" class="md-tabs__link">
        
  
  
    
  
  API Reference

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../examples/" class="md-tabs__link">
        
  
  
    
  
  Examples

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../architecture/" class="md-tabs__link">
        
  
  
    
  
  Architecture

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../chromium-comparison/" class="md-tabs__link">
        
  
  
    
  
  Chromium Comparison

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../development/" class="md-tabs__link">
        
  
  
    
  
  Development

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../advanced/" class="md-tabs__link">
        
  
  
    
  
  Advanced Topics

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="WebNN Python API" class="md-nav__button md-logo" aria-label="WebNN Python API" data-md-component="logo">
      
  <img src="../logo/rustnn.png" alt="logo">

    </a>
    WebNN Python API
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/your-org/rustnn" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
  </div>
  <div class="md-source__repository">
    your-org/rustnn
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Home
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting-started/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Getting Started
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../api-reference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    API Reference
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Examples
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../architecture/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Architecture
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../chromium-comparison/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Chromium Comparison
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../development/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Development
  

    
  </span>
  
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../advanced/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    
  
    Advanced Topics
  

    
  </span>
  
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#target-overview" class="md-nav__link">
    <span class="md-ellipsis">
      
        [TARGET] Overview
      
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tensorrt-background" class="md-nav__link">
    <span class="md-ellipsis">
      
        TensorRT Background
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="TensorRT Background">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#what-is-tensorrt" class="md-nav__link">
    <span class="md-ellipsis">
      
        What is TensorRT?
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#tensorrt-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      
        TensorRT Architecture
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#supported-operations" class="md-nav__link">
    <span class="md-ellipsis">
      
        Supported Operations
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#integration-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      
        Integration Architecture
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Integration Architecture">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#following-rustnn-patterns" class="md-nav__link">
    <span class="md-ellipsis">
      
        Following rustnn Patterns
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#file-structure" class="md-nav__link">
    <span class="md-ellipsis">
      
        File Structure
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementation-plan" class="md-nav__link">
    <span class="md-ellipsis">
      
        Implementation Plan
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Implementation Plan">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#phase-1-executor-onnx-tensorrt-engine" class="md-nav__link">
    <span class="md-ellipsis">
      
        Phase 1: Executor (ONNX → TensorRT Engine)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#phase-2-feature-flag-dependencies" class="md-nav__link">
    <span class="md-ellipsis">
      
        Phase 2: Feature Flag &amp; Dependencies
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#phase-3-registration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Phase 3: Registration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#phase-4-python-api-integration" class="md-nav__link">
    <span class="md-ellipsis">
      
        Phase 4: Python API Integration
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#phase-5-engine-caching-performance-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      
        Phase 5: Engine Caching (Performance Optimization)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#stats-operation-coverage-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      
        [STATS] Operation Coverage Analysis
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="[STATS] Operation Coverage Analysis">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#webnn-operations-tensorrt-support" class="md-nav__link">
    <span class="md-ellipsis">
      
        WebNN Operations → TensorRT Support
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#challenges-solutions" class="md-nav__link">
    <span class="md-ellipsis">
      
        Challenges &amp; Solutions
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Challenges &amp; Solutions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#challenge-1-rust-bindings-maturity" class="md-nav__link">
    <span class="md-ellipsis">
      
        Challenge 1: Rust Bindings Maturity
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#challenge-2-cuda-dependency" class="md-nav__link">
    <span class="md-ellipsis">
      
        Challenge 2: CUDA Dependency
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#challenge-3-engine-build-time" class="md-nav__link">
    <span class="md-ellipsis">
      
        Challenge 3: Engine Build Time
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#challenge-4-precision-selection" class="md-nav__link">
    <span class="md-ellipsis">
      
        Challenge 4: Precision Selection
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#challenge-5-platform-support" class="md-nav__link">
    <span class="md-ellipsis">
      
        Challenge 5: Platform Support
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#challenge-6-dynamic-shapes" class="md-nav__link">
    <span class="md-ellipsis">
      
        Challenge 6: Dynamic Shapes
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#target-implementation-roadmap" class="md-nav__link">
    <span class="md-ellipsis">
      
        [TARGET] Implementation Roadmap
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="[TARGET] Implementation Roadmap">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#phase-1-proof-of-concept-2-3-days" class="md-nav__link">
    <span class="md-ellipsis">
      
        Phase 1: Proof of Concept (2-3 days)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#phase-2-core-functionality-5-7-days" class="md-nav__link">
    <span class="md-ellipsis">
      
        Phase 2: Core Functionality (5-7 days)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#phase-3-performance-optimization-3-5-days" class="md-nav__link">
    <span class="md-ellipsis">
      
        Phase 3: Performance Optimization (3-5 days)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#phase-4-python-integration-2-3-days" class="md-nav__link">
    <span class="md-ellipsis">
      
        Phase 4: Python Integration (2-3 days)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#phase-5-documentation-testing-2-3-days" class="md-nav__link">
    <span class="md-ellipsis">
      
        Phase 5: Documentation &amp; Testing (2-3 days)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#phase-6-advanced-features-future" class="md-nav__link">
    <span class="md-ellipsis">
      
        Phase 6: Advanced Features (Future)
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#testing-strategy" class="md-nav__link">
    <span class="md-ellipsis">
      
        Testing Strategy
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Testing Strategy">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#unit-tests-rust" class="md-nav__link">
    <span class="md-ellipsis">
      
        Unit Tests (Rust)
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#python-tests" class="md-nav__link">
    <span class="md-ellipsis">
      
        Python Tests
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-benchmarks" class="md-nav__link">
    <span class="md-ellipsis">
      
        Performance Benchmarks
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#makefile-targets" class="md-nav__link">
    <span class="md-ellipsis">
      
        Makefile Targets
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    <span class="md-ellipsis">
      
        References
      
    </span>
  </a>
  
    <nav class="md-nav" aria-label="References">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#tensorrt-resources" class="md-nav__link">
    <span class="md-ellipsis">
      
        TensorRT Resources
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#onnx-tensorrt" class="md-nav__link">
    <span class="md-ellipsis">
      
        ONNX-TensorRT
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rust-bindings" class="md-nav__link">
    <span class="md-ellipsis">
      
        Rust Bindings
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#webnn-spec" class="md-nav__link">
    <span class="md-ellipsis">
      
        WebNN Spec
      
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#related-projects" class="md-nav__link">
    <span class="md-ellipsis">
      
        Related Projects
      
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      
        Summary
      
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="tensorrt-integration-guide">TensorRT Integration Guide<a class="headerlink" href="#tensorrt-integration-guide" title="Permanent link">&para;</a></h1>
<p><strong>Date:</strong> December 8, 2024
<strong>Purpose:</strong> Guide for adding NVIDIA TensorRT converter and executor to rustnn</p>
<hr />
<h2 id="target-overview">[TARGET] Overview<a class="headerlink" href="#target-overview" title="Permanent link">&para;</a></h2>
<p>This document outlines the integration of <a href="https://developer.nvidia.com/tensorrt">NVIDIA TensorRT</a> as a fourth execution backend for rustnn, optimized for NVIDIA GPU inference alongside ONNX Runtime, CoreML, and GGML.</p>
<p><strong>Why TensorRT?</strong>
- <strong>GPU-optimized inference</strong>: Best-in-class performance on NVIDIA GPUs (RTX, A100, H100)
- <strong>Advanced quantization</strong>: FP16, INT8, INT4, FP8, FP4 for maximum throughput
- <strong>JIT optimization</strong>: Just-In-Time compilation for specific GPU architectures
- <strong>Production-ready</strong>: Widely deployed in NVIDIA-accelerated inference (Triton, TensorRT-LLM)
- <strong>ONNX-native</strong>: Primary import via ONNX format (perfect match for rustnn)</p>
<p><strong>TensorRT for RTX (New in 2025):</strong>
- Lightweight library (&lt;200 MB) optimized for Windows 11 + NVIDIA RTX GPUs
- 50%+ performance improvement vs baseline DirectML
- JIT compilation in &lt;30 seconds
- Supports Turing through Blackwell GPU generations</p>
<hr />
<h2 id="tensorrt-background">TensorRT Background<a class="headerlink" href="#tensorrt-background" title="Permanent link">&para;</a></h2>
<h3 id="what-is-tensorrt">What is TensorRT?<a class="headerlink" href="#what-is-tensorrt" title="Permanent link">&para;</a></h3>
<p>TensorRT is NVIDIA's high-performance deep learning inference SDK. It optimizes trained models through:
- <strong>Layer fusion</strong>: Combines operations to reduce kernel launches
- <strong>Precision calibration</strong>: INT8/FP16 quantization with minimal accuracy loss
- <strong>Kernel auto-tuning</strong>: Selects fastest implementation for target GPU
- <strong>Dynamic tensor memory</strong>: Minimizes memory footprint</p>
<p><strong>Key Resources:</strong>
- <a href="https://docs.nvidia.com/deeplearning/tensorrt/latest/index.html">TensorRT Documentation</a>
- <a href="https://developer.nvidia.com/tensorrt">TensorRT SDK</a>
- <a href="https://docs.nvidia.com/deeplearning/tensorrt-rtx/latest/index.html">TensorRT for RTX (Windows 11)</a>
- <a href="https://github.com/onnx/onnx-tensorrt">ONNX-TensorRT GitHub</a></p>
<h3 id="tensorrt-architecture">TensorRT Architecture<a class="headerlink" href="#tensorrt-architecture" title="Permanent link">&para;</a></h3>
<p><strong>Core Workflow:</strong>
<div class="language-text highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>ONNX Model → TensorRT Builder → Optimized Engine → Inference Runtime
</span></code></pre></div></p>
<p><strong>Key Concepts:</strong>
1. <strong>Builder (<code>IBuilder</code>)</strong>: Configures optimization settings (precision, batch size, workspace)
2. <strong>Network (<code>INetworkDefinition</code>)</strong>: Graph of layers and tensors
3. <strong>Engine (<code>ICudaEngine</code>)</strong>: Optimized executable for specific GPU + precision
4. <strong>Context (<code>IExecutionContext</code>)</strong>: Runtime state for executing inference
5. <strong>Parser (<code>IParser</code>)</strong>: Imports ONNX models into TensorRT network</p>
<p><strong>Optimization Pipeline:</strong>
<div class="language-rust highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="c1">// 1. Create builder and network</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="kd">let</span><span class="w"> </span><span class="n">builder</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_infer_builder</span><span class="p">();</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="kd">let</span><span class="w"> </span><span class="n">network</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">builder</span><span class="p">.</span><span class="n">create_network</span><span class="p">();</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="c1">// 2. Parse ONNX model</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a><span class="kd">let</span><span class="w"> </span><span class="n">parser</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_onnx_parser</span><span class="p">(</span><span class="n">network</span><span class="p">);</span>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a><span class="n">parser</span><span class="p">.</span><span class="n">parse_from_file</span><span class="p">(</span><span class="s">&quot;model.onnx&quot;</span><span class="p">);</span>
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a><span class="c1">// 3. Build optimized engine</span>
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a><span class="kd">let</span><span class="w"> </span><span class="n">config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">builder</span><span class="p">.</span><span class="n">create_builder_config</span><span class="p">();</span>
</span><span id="__span-1-11"><a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a><span class="n">config</span><span class="p">.</span><span class="n">set_flag</span><span class="p">(</span><span class="n">BuilderFlag</span><span class="p">::</span><span class="n">FP16</span><span class="p">);</span><span class="w">  </span><span class="c1">// Enable FP16</span>
</span><span id="__span-1-12"><a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a><span class="kd">let</span><span class="w"> </span><span class="n">engine</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">builder</span><span class="p">.</span><span class="n">build_engine</span><span class="p">(</span><span class="n">network</span><span class="p">,</span><span class="w"> </span><span class="n">config</span><span class="p">);</span>
</span><span id="__span-1-13"><a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a>
</span><span id="__span-1-14"><a id="__codelineno-1-14" name="__codelineno-1-14" href="#__codelineno-1-14"></a><span class="c1">// 4. Execute inference</span>
</span><span id="__span-1-15"><a id="__codelineno-1-15" name="__codelineno-1-15" href="#__codelineno-1-15"></a><span class="kd">let</span><span class="w"> </span><span class="n">context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">engine</span><span class="p">.</span><span class="n">create_execution_context</span><span class="p">();</span>
</span><span id="__span-1-16"><a id="__codelineno-1-16" name="__codelineno-1-16" href="#__codelineno-1-16"></a><span class="n">context</span><span class="p">.</span><span class="n">execute_v2</span><span class="p">(</span><span class="o">&amp;</span><span class="n">bindings</span><span class="p">);</span><span class="w">  </span><span class="c1">// Run inference</span>
</span></code></pre></div></p>
<h3 id="supported-operations">Supported Operations<a class="headerlink" href="#supported-operations" title="Permanent link">&para;</a></h3>
<p><strong>300+ ONNX Operators</strong> (opset 9-20) including:</p>
<p><strong>Binary Operations:</strong>
- Add, Sub, Mul, Div, MatMul, Pow
- Broadcasting support</p>
<p><strong>Activations:</strong>
- Relu, Sigmoid, Tanh, Softmax, Gelu, Elu, LeakyRelu, PRelu, Selu, HardSigmoid, HardSwish, Softplus, Softsign</p>
<p><strong>Convolution &amp; Pooling:</strong>
- Conv, ConvTranspose (2D and 3D)
- MaxPool, AveragePool, GlobalAveragePool, GlobalMaxPool
- LpPool (with restrictions)</p>
<p><strong>Normalization:</strong>
- BatchNormalization, InstanceNormalization, LayerNormalization, GroupNormalization, LRN</p>
<p><strong>Reduction:</strong>
- ReduceSum, ReduceMean, ReduceMax, ReduceMin, ReduceProd
- ReduceL1, ReduceL2, ReduceLogSum, ReduceLogSumExp, ReduceSumSquare</p>
<p><strong>Tensor Manipulation:</strong>
- Reshape, Transpose, Concat, Split, Slice, Gather, Scatter, Squeeze, Unsqueeze, Expand, Pad, Tile</p>
<p><strong>Comparison &amp; Logic:</strong>
- Equal, Greater, GreaterOrEqual, Less, LessOrEqual
- And, Or, Xor, Not</p>
<p><strong>Math Functions:</strong>
- Abs, Neg, Ceil, Floor, Round, Sqrt, Exp, Log, Sin, Cos, Tan, Asin, Acos, Atan, Sinh, Cosh, Tanh, Asinh, Acosh, Atanh, Erf, Sign, Reciprocal</p>
<p><strong>Advanced:</strong>
- LSTM, GRU (with restrictions)
- Attention mechanisms
- Einsum
- TopK, ArgMax, ArgMin
- Cast, Clip, Where</p>
<p><strong>Quantization:</strong>
- QuantizeLinear, DequantizeLinear</p>
<p><strong>Data Types:</strong>
DOUBLE, FLOAT32, FLOAT16, BFLOAT16, INT32, INT64, FP8, INT8, INT4, UINT8, BOOL</p>
<p><strong>Important Limitations:</strong>
- DOUBLE cast to FLOAT32 (with clamping)
- UINT8 only for input/output tensors
- INT8/INT4/FP8 require quantization from FP32/FP16
- Some ops restricted to 2D/3D (e.g., pooling)</p>
<hr />
<h2 id="integration-architecture">Integration Architecture<a class="headerlink" href="#integration-architecture" title="Permanent link">&para;</a></h2>
<h3 id="following-rustnn-patterns">Following rustnn Patterns<a class="headerlink" href="#following-rustnn-patterns" title="Permanent link">&para;</a></h3>
<p>rustnn uses a <strong>converter + executor</strong> pattern:</p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>WebNN GraphInfo → Converter → ONNX → TensorRT Engine → Executor → Results
</span></code></pre></div>
<p><strong>Existing Backends:</strong>
1. <strong>ONNX Runtime</strong>: Cross-platform, protobuf → ONNX Runtime execution
2. <strong>CoreML</strong>: macOS-only, protobuf → CoreML execution
3. <strong>GGML</strong>: CPU-optimized, in-memory graph → GGML execution</p>
<p><strong>New TensorRT Backend:</strong>
4. <strong>TensorRT</strong>: NVIDIA GPU, ONNX → TensorRT Engine → GPU execution</p>
<p><strong>Key Advantage:</strong> We already have ONNX converter! TensorRT can consume ONNX directly.</p>
<h3 id="file-structure">File Structure<a class="headerlink" href="#file-structure" title="Permanent link">&para;</a></h3>
<div class="language-text highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a>src/
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a> converters/
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>    mod.rs              # Already has OnnxConverter (reuse!)
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a>    onnx.rs
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a>    coreml_mlprogram.rs
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>    ggml.rs
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>    tensorrt.rs         # NEW: TensorRT-specific converter (optional)
</span><span id="__span-3-8"><a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a> executors/
</span><span id="__span-3-9"><a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a>    mod.rs              # Add #[cfg(feature = &quot;tensorrt-runtime&quot;)]
</span><span id="__span-3-10"><a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>    onnx.rs
</span><span id="__span-3-11"><a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a>    coreml.rs
</span><span id="__span-3-12"><a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a>    ggml.rs
</span><span id="__span-3-13"><a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a>    tensorrt.rs         # NEW: TensorRT executor
</span><span id="__span-3-14"><a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a> python/
</span><span id="__span-3-15"><a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a>     context.rs          # Add Backend::TensorRT variant
</span></code></pre></div>
<hr />
<h2 id="implementation-plan">Implementation Plan<a class="headerlink" href="#implementation-plan" title="Permanent link">&para;</a></h2>
<h3 id="phase-1-executor-onnx-tensorrt-engine">Phase 1: Executor (ONNX → TensorRT Engine)<a class="headerlink" href="#phase-1-executor-onnx-tensorrt-engine" title="Permanent link">&para;</a></h3>
<p><strong>File:</strong> <code>src/executors/tensorrt.rs</code></p>
<p><strong>Feature Gate:</strong> <code>#[cfg(feature = "tensorrt-runtime")]</code></p>
<p><strong>Strategy:</strong> Reuse existing ONNX converter, build TensorRT engine from ONNX bytes</p>
<p><strong>Implementation:</strong>
<div class="language-rust highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="cp">#![cfg(feature = </span><span class="s">&quot;tensorrt-runtime&quot;</span><span class="cp">)]</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a><span class="k">use</span><span class="w"> </span><span class="k">crate</span><span class="p">::</span><span class="n">error</span><span class="p">::</span><span class="n">GraphError</span><span class="p">;</span>
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a><span class="k">use</span><span class="w"> </span><span class="k">crate</span><span class="p">::</span><span class="n">graph</span><span class="p">::{</span><span class="n">GraphInfo</span><span class="p">,</span><span class="w"> </span><span class="n">OperandDescriptor</span><span class="p">};</span>
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a><span class="k">use</span><span class="w"> </span><span class="n">std</span><span class="p">::</span><span class="n">collections</span><span class="p">::</span><span class="n">HashMap</span><span class="p">;</span>
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a>
</span><span id="__span-4-7"><a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a><span class="k">pub</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="nc">TensorRTOutput</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-4-8"><a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a><span class="w">    </span><span class="k">pub</span><span class="w"> </span><span class="n">name</span><span class="p">:</span><span class="w"> </span><span class="nb">String</span><span class="p">,</span>
</span><span id="__span-4-9"><a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a><span class="w">    </span><span class="k">pub</span><span class="w"> </span><span class="n">shape</span><span class="p">:</span><span class="w"> </span><span class="nb">Vec</span><span class="o">&lt;</span><span class="kt">usize</span><span class="o">&gt;</span><span class="p">,</span>
</span><span id="__span-4-10"><a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a><span class="w">    </span><span class="k">pub</span><span class="w"> </span><span class="n">data</span><span class="p">:</span><span class="w"> </span><span class="nb">Vec</span><span class="o">&lt;</span><span class="kt">f32</span><span class="o">&gt;</span><span class="p">,</span>
</span><span id="__span-4-11"><a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a><span class="p">}</span>
</span><span id="__span-4-12"><a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a>
</span><span id="__span-4-13"><a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a><span class="k">pub</span><span class="w"> </span><span class="k">struct</span><span class="w"> </span><span class="nc">TensorRTInput</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-4-14"><a id="__codelineno-4-14" name="__codelineno-4-14" href="#__codelineno-4-14"></a><span class="w">    </span><span class="k">pub</span><span class="w"> </span><span class="n">name</span><span class="p">:</span><span class="w"> </span><span class="nb">String</span><span class="p">,</span>
</span><span id="__span-4-15"><a id="__codelineno-4-15" name="__codelineno-4-15" href="#__codelineno-4-15"></a><span class="w">    </span><span class="k">pub</span><span class="w"> </span><span class="n">shape</span><span class="p">:</span><span class="w"> </span><span class="nb">Vec</span><span class="o">&lt;</span><span class="kt">usize</span><span class="o">&gt;</span><span class="p">,</span>
</span><span id="__span-4-16"><a id="__codelineno-4-16" name="__codelineno-4-16" href="#__codelineno-4-16"></a><span class="w">    </span><span class="k">pub</span><span class="w"> </span><span class="n">data</span><span class="p">:</span><span class="w"> </span><span class="nb">Vec</span><span class="o">&lt;</span><span class="kt">f32</span><span class="o">&gt;</span><span class="p">,</span>
</span><span id="__span-4-17"><a id="__codelineno-4-17" name="__codelineno-4-17" href="#__codelineno-4-17"></a><span class="p">}</span>
</span><span id="__span-4-18"><a id="__codelineno-4-18" name="__codelineno-4-18" href="#__codelineno-4-18"></a>
</span><span id="__span-4-19"><a id="__codelineno-4-19" name="__codelineno-4-19" href="#__codelineno-4-19"></a><span class="sd">/// Execute TensorRT inference from ONNX model bytes</span>
</span><span id="__span-4-20"><a id="__codelineno-4-20" name="__codelineno-4-20" href="#__codelineno-4-20"></a><span class="k">pub</span><span class="w"> </span><span class="k">fn</span><span class="w"> </span><span class="nf">run_tensorrt_with_inputs</span><span class="p">(</span>
</span><span id="__span-4-21"><a id="__codelineno-4-21" name="__codelineno-4-21" href="#__codelineno-4-21"></a><span class="w">    </span><span class="n">onnx_model</span><span class="p">:</span><span class="w"> </span><span class="kp">&amp;</span><span class="p">[</span><span class="kt">u8</span><span class="p">],</span>
</span><span id="__span-4-22"><a id="__codelineno-4-22" name="__codelineno-4-22" href="#__codelineno-4-22"></a><span class="w">    </span><span class="n">inputs</span><span class="p">:</span><span class="w"> </span><span class="nc">HashMap</span><span class="o">&lt;</span><span class="nb">String</span><span class="p">,</span><span class="w"> </span><span class="n">TensorRTInput</span><span class="o">&gt;</span><span class="p">,</span>
</span><span id="__span-4-23"><a id="__codelineno-4-23" name="__codelineno-4-23" href="#__codelineno-4-23"></a><span class="w">    </span><span class="n">precision</span><span class="p">:</span><span class="w"> </span><span class="nc">TensorRTPrecision</span><span class="p">,</span>
</span><span id="__span-4-24"><a id="__codelineno-4-24" name="__codelineno-4-24" href="#__codelineno-4-24"></a><span class="p">)</span><span class="w"> </span><span class="p">-&gt;</span><span class="w"> </span><span class="nb">Result</span><span class="o">&lt;</span><span class="nb">Vec</span><span class="o">&lt;</span><span class="n">TensorRTOutput</span><span class="o">&gt;</span><span class="p">,</span><span class="w"> </span><span class="n">GraphError</span><span class="o">&gt;</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-4-25"><a id="__codelineno-4-25" name="__codelineno-4-25" href="#__codelineno-4-25"></a><span class="w">    </span><span class="c1">// 1. Create TensorRT builder</span>
</span><span id="__span-4-26"><a id="__codelineno-4-26" name="__codelineno-4-26" href="#__codelineno-4-26"></a><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">logger</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_logger</span><span class="p">();</span>
</span><span id="__span-4-27"><a id="__codelineno-4-27" name="__codelineno-4-27" href="#__codelineno-4-27"></a><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">builder</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_infer_builder</span><span class="p">(</span><span class="o">&amp;</span><span class="n">logger</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
</span><span id="__span-4-28"><a id="__codelineno-4-28" name="__codelineno-4-28" href="#__codelineno-4-28"></a>
</span><span id="__span-4-29"><a id="__codelineno-4-29" name="__codelineno-4-29" href="#__codelineno-4-29"></a><span class="w">    </span><span class="c1">// 2. Parse ONNX model</span>
</span><span id="__span-4-30"><a id="__codelineno-4-30" name="__codelineno-4-30" href="#__codelineno-4-30"></a><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">network_flags</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="k">u32</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">NetworkDefinitionCreationFlag</span><span class="p">::</span><span class="n">ExplicitBatchDimensions</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="kt">u32</span><span class="p">;</span>
</span><span id="__span-4-31"><a id="__codelineno-4-31" name="__codelineno-4-31" href="#__codelineno-4-31"></a><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">network</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">builder</span><span class="p">.</span><span class="n">create_network_v2</span><span class="p">(</span><span class="n">network_flags</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
</span><span id="__span-4-32"><a id="__codelineno-4-32" name="__codelineno-4-32" href="#__codelineno-4-32"></a>
</span><span id="__span-4-33"><a id="__codelineno-4-33" name="__codelineno-4-33" href="#__codelineno-4-33"></a><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">parser</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_onnx_parser</span><span class="p">(</span><span class="o">&amp;</span><span class="n">network</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">logger</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
</span><span id="__span-4-34"><a id="__codelineno-4-34" name="__codelineno-4-34" href="#__codelineno-4-34"></a><span class="w">    </span><span class="n">parser</span><span class="p">.</span><span class="n">parse</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
</span><span id="__span-4-35"><a id="__codelineno-4-35" name="__codelineno-4-35" href="#__codelineno-4-35"></a>
</span><span id="__span-4-36"><a id="__codelineno-4-36" name="__codelineno-4-36" href="#__codelineno-4-36"></a><span class="w">    </span><span class="c1">// 3. Configure builder</span>
</span><span id="__span-4-37"><a id="__codelineno-4-37" name="__codelineno-4-37" href="#__codelineno-4-37"></a><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">config</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">builder</span><span class="p">.</span><span class="n">create_builder_config</span><span class="p">()</span><span class="o">?</span><span class="p">;</span>
</span><span id="__span-4-38"><a id="__codelineno-4-38" name="__codelineno-4-38" href="#__codelineno-4-38"></a><span class="w">    </span><span class="n">config</span><span class="p">.</span><span class="n">set_memory_pool_limit</span><span class="p">(</span><span class="n">MemoryPoolType</span><span class="p">::</span><span class="n">Workspace</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="mi">30</span><span class="p">)</span><span class="o">?</span><span class="p">;</span><span class="w"> </span><span class="c1">// 1GB</span>
</span><span id="__span-4-39"><a id="__codelineno-4-39" name="__codelineno-4-39" href="#__codelineno-4-39"></a>
</span><span id="__span-4-40"><a id="__codelineno-4-40" name="__codelineno-4-40" href="#__codelineno-4-40"></a><span class="w">    </span><span class="c1">// Set precision mode</span>
</span><span id="__span-4-41"><a id="__codelineno-4-41" name="__codelineno-4-41" href="#__codelineno-4-41"></a><span class="w">    </span><span class="k">match</span><span class="w"> </span><span class="n">precision</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-4-42"><a id="__codelineno-4-42" name="__codelineno-4-42" href="#__codelineno-4-42"></a><span class="w">        </span><span class="n">TensorRTPrecision</span><span class="p">::</span><span class="n">FP32</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="p">{},</span>
</span><span id="__span-4-43"><a id="__codelineno-4-43" name="__codelineno-4-43" href="#__codelineno-4-43"></a><span class="w">        </span><span class="n">TensorRTPrecision</span><span class="p">::</span><span class="n">FP16</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">config</span><span class="p">.</span><span class="n">set_flag</span><span class="p">(</span><span class="n">BuilderFlag</span><span class="p">::</span><span class="n">FP16</span><span class="p">)</span><span class="o">?</span><span class="p">,</span>
</span><span id="__span-4-44"><a id="__codelineno-4-44" name="__codelineno-4-44" href="#__codelineno-4-44"></a><span class="w">        </span><span class="n">TensorRTPrecision</span><span class="p">::</span><span class="n">INT8</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">config</span><span class="p">.</span><span class="n">set_flag</span><span class="p">(</span><span class="n">BuilderFlag</span><span class="p">::</span><span class="n">INT8</span><span class="p">)</span><span class="o">?</span><span class="p">,</span>
</span><span id="__span-4-45"><a id="__codelineno-4-45" name="__codelineno-4-45" href="#__codelineno-4-45"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-4-46"><a id="__codelineno-4-46" name="__codelineno-4-46" href="#__codelineno-4-46"></a>
</span><span id="__span-4-47"><a id="__codelineno-4-47" name="__codelineno-4-47" href="#__codelineno-4-47"></a><span class="w">    </span><span class="c1">// 4. Build engine</span>
</span><span id="__span-4-48"><a id="__codelineno-4-48" name="__codelineno-4-48" href="#__codelineno-4-48"></a><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">engine</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">builder</span><span class="p">.</span><span class="n">build_serialized_network</span><span class="p">(</span><span class="o">&amp;</span><span class="n">network</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">config</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
</span><span id="__span-4-49"><a id="__codelineno-4-49" name="__codelineno-4-49" href="#__codelineno-4-49"></a><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">runtime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_infer_runtime</span><span class="p">(</span><span class="o">&amp;</span><span class="n">logger</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
</span><span id="__span-4-50"><a id="__codelineno-4-50" name="__codelineno-4-50" href="#__codelineno-4-50"></a><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">engine</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">runtime</span><span class="p">.</span><span class="n">deserialize_cuda_engine</span><span class="p">(</span><span class="o">&amp;</span><span class="n">engine</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
</span><span id="__span-4-51"><a id="__codelineno-4-51" name="__codelineno-4-51" href="#__codelineno-4-51"></a>
</span><span id="__span-4-52"><a id="__codelineno-4-52" name="__codelineno-4-52" href="#__codelineno-4-52"></a><span class="w">    </span><span class="c1">// 5. Create execution context</span>
</span><span id="__span-4-53"><a id="__codelineno-4-53" name="__codelineno-4-53" href="#__codelineno-4-53"></a><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">context</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">engine</span><span class="p">.</span><span class="n">create_execution_context</span><span class="p">()</span><span class="o">?</span><span class="p">;</span>
</span><span id="__span-4-54"><a id="__codelineno-4-54" name="__codelineno-4-54" href="#__codelineno-4-54"></a>
</span><span id="__span-4-55"><a id="__codelineno-4-55" name="__codelineno-4-55" href="#__codelineno-4-55"></a><span class="w">    </span><span class="c1">// 6. Allocate GPU buffers and copy inputs</span>
</span><span id="__span-4-56"><a id="__codelineno-4-56" name="__codelineno-4-56" href="#__codelineno-4-56"></a><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">bindings</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">allocate_and_copy_inputs</span><span class="p">(</span><span class="o">&amp;</span><span class="n">engine</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
</span><span id="__span-4-57"><a id="__codelineno-4-57" name="__codelineno-4-57" href="#__codelineno-4-57"></a>
</span><span id="__span-4-58"><a id="__codelineno-4-58" name="__codelineno-4-58" href="#__codelineno-4-58"></a><span class="w">    </span><span class="c1">// 7. Execute inference</span>
</span><span id="__span-4-59"><a id="__codelineno-4-59" name="__codelineno-4-59" href="#__codelineno-4-59"></a><span class="w">    </span><span class="n">context</span><span class="p">.</span><span class="n">execute_v2</span><span class="p">(</span><span class="o">&amp;</span><span class="n">bindings</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
</span><span id="__span-4-60"><a id="__codelineno-4-60" name="__codelineno-4-60" href="#__codelineno-4-60"></a>
</span><span id="__span-4-61"><a id="__codelineno-4-61" name="__codelineno-4-61" href="#__codelineno-4-61"></a><span class="w">    </span><span class="c1">// 8. Copy outputs back to CPU</span>
</span><span id="__span-4-62"><a id="__codelineno-4-62" name="__codelineno-4-62" href="#__codelineno-4-62"></a><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">copy_outputs_from_gpu</span><span class="p">(</span><span class="o">&amp;</span><span class="n">engine</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">bindings</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
</span><span id="__span-4-63"><a id="__codelineno-4-63" name="__codelineno-4-63" href="#__codelineno-4-63"></a>
</span><span id="__span-4-64"><a id="__codelineno-4-64" name="__codelineno-4-64" href="#__codelineno-4-64"></a><span class="w">    </span><span class="nb">Ok</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="__span-4-65"><a id="__codelineno-4-65" name="__codelineno-4-65" href="#__codelineno-4-65"></a><span class="p">}</span>
</span><span id="__span-4-66"><a id="__codelineno-4-66" name="__codelineno-4-66" href="#__codelineno-4-66"></a>
</span><span id="__span-4-67"><a id="__codelineno-4-67" name="__codelineno-4-67" href="#__codelineno-4-67"></a><span class="cp">#[derive(Debug, Clone, Copy)]</span>
</span><span id="__span-4-68"><a id="__codelineno-4-68" name="__codelineno-4-68" href="#__codelineno-4-68"></a><span class="k">pub</span><span class="w"> </span><span class="k">enum</span><span class="w"> </span><span class="nc">TensorRTPrecision</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-4-69"><a id="__codelineno-4-69" name="__codelineno-4-69" href="#__codelineno-4-69"></a><span class="w">    </span><span class="n">FP32</span><span class="p">,</span>
</span><span id="__span-4-70"><a id="__codelineno-4-70" name="__codelineno-4-70" href="#__codelineno-4-70"></a><span class="w">    </span><span class="n">FP16</span><span class="p">,</span>
</span><span id="__span-4-71"><a id="__codelineno-4-71" name="__codelineno-4-71" href="#__codelineno-4-71"></a><span class="w">    </span><span class="n">INT8</span><span class="p">,</span>
</span><span id="__span-4-72"><a id="__codelineno-4-72" name="__codelineno-4-72" href="#__codelineno-4-72"></a><span class="p">}</span>
</span></code></pre></div></p>
<p><strong>Key Challenges:</strong>
1. <strong>Rust bindings</strong>: Use <code>tensorrt-rs</code> or <code>easy-tensorrt-sys</code> (FFI to C++ API)
2. <strong>GPU memory management</strong>: Allocate CUDA buffers for inputs/outputs
3. <strong>Engine caching</strong>: Serialized engines can be cached for faster startup
4. <strong>Precision selection</strong>: FP32/FP16/INT8 based on device hints
5. <strong>Batch size</strong>: Dynamic batch support vs fixed batch</p>
<h3 id="phase-2-feature-flag-dependencies">Phase 2: Feature Flag &amp; Dependencies<a class="headerlink" href="#phase-2-feature-flag-dependencies" title="Permanent link">&para;</a></h3>
<p><strong>File:</strong> <code>Cargo.toml</code></p>
<p><strong>Changes:</strong>
<div class="language-toml highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="k">[features]</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="n">default</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[]</span>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a><span class="n">coreml-runtime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;objc&quot;</span><span class="p">]</span>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a><span class="n">onnx-runtime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;onnxruntime&quot;</span><span class="p">]</span>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a><span class="n">ggml-runtime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;ggml&quot;</span><span class="p">]</span>
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a><span class="n">tensorrt-runtime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;tensorrt-rs&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;cuda-runtime&quot;</span><span class="p">]</span><span class="w">  </span><span class="c1"># NEW</span>
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a><span class="k">[dependencies]</span>
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a><span class="c1"># ... existing dependencies ...</span>
</span><span id="__span-5-10"><a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a><span class="n">tensorrt-rs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">version</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s2">&quot;0.8&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">optional</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="kc">true</span><span class="w"> </span><span class="p">}</span><span class="w">  </span><span class="c1"># NEW</span>
</span><span id="__span-5-11"><a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a><span class="n">cuda-runtime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">version</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s2">&quot;0.7&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">optional</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="kc">true</span><span class="w"> </span><span class="p">}</span><span class="w">  </span><span class="c1"># NEW</span>
</span><span id="__span-5-12"><a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a><span class="c1"># Alternative: easy-tensorrt-sys for more recent bindings</span>
</span></code></pre></div></p>
<p><strong>Rust Bindings Options:</strong></p>
<table>
<thead>
<tr>
<th>Crate</th>
<th>Status</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>tensorrt-rs</code></td>
<td>Older (2020)</td>
<td>Supports TensorRT 5-7, may need fork</td>
</tr>
<tr>
<td><code>easy-tensorrt-sys</code></td>
<td>Newer fork</td>
<td>Uses <code>cudarc</code> instead of old <code>cuda-rs</code></td>
</tr>
<tr>
<td>Custom FFI</td>
<td>Most control</td>
<td>Bindgen to TensorRT C++ API</td>
</tr>
</tbody>
</table>
<p><strong>Recommendation:</strong> Start with <code>easy-tensorrt-sys</code> or custom FFI for TensorRT 10.x support</p>
<h3 id="phase-3-registration">Phase 3: Registration<a class="headerlink" href="#phase-3-registration" title="Permanent link">&para;</a></h3>
<p><strong>File:</strong> <code>src/executors/mod.rs</code></p>
<p><strong>Changes:</strong>
<div class="language-rust highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="cp">#[cfg(all(target_os = </span><span class="s">&quot;macos&quot;</span><span class="cp">, feature = </span><span class="s">&quot;coreml-runtime&quot;</span><span class="cp">))]</span>
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a><span class="k">pub</span><span class="w"> </span><span class="k">mod</span><span class="w"> </span><span class="nn">coreml</span><span class="p">;</span>
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a><span class="cp">#[cfg(feature = </span><span class="s">&quot;onnx-runtime&quot;</span><span class="cp">)]</span>
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a><span class="k">pub</span><span class="w"> </span><span class="k">mod</span><span class="w"> </span><span class="nn">onnx</span><span class="p">;</span>
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a><span class="cp">#[cfg(feature = </span><span class="s">&quot;ggml-runtime&quot;</span><span class="cp">)]</span>
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a><span class="k">pub</span><span class="w"> </span><span class="k">mod</span><span class="w"> </span><span class="nn">ggml</span><span class="p">;</span>
</span><span id="__span-6-7"><a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a><span class="cp">#[cfg(feature = </span><span class="s">&quot;tensorrt-runtime&quot;</span><span class="cp">)]</span><span class="w">  </span><span class="c1">// NEW</span>
</span><span id="__span-6-8"><a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a><span class="k">pub</span><span class="w"> </span><span class="k">mod</span><span class="w"> </span><span class="nn">tensorrt</span><span class="p">;</span>
</span></code></pre></div></p>
<p><strong>File:</strong> <code>src/converters/mod.rs</code></p>
<p><strong>No changes needed!</strong> Reuse existing <code>OnnxConverter</code> to generate ONNX bytes, then TensorRT executor parses ONNX directly.</p>
<h3 id="phase-4-python-api-integration">Phase 4: Python API Integration<a class="headerlink" href="#phase-4-python-api-integration" title="Permanent link">&para;</a></h3>
<p><strong>File:</strong> <code>src/python/context.rs</code></p>
<p><strong>Changes:</strong>
<div class="language-rust highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="cp">#[derive(Debug, Clone)]</span>
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="k">enum</span><span class="w"> </span><span class="nc">Backend</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a><span class="w">    </span><span class="n">OnnxCpu</span><span class="p">,</span>
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a><span class="w">    </span><span class="n">OnnxGpu</span><span class="p">,</span>
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a><span class="w">    </span><span class="n">CoreML</span><span class="p">,</span>
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a><span class="w">    </span><span class="n">Ggml</span><span class="p">,</span>
</span><span id="__span-7-7"><a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a><span class="w">    </span><span class="n">TensorRT</span><span class="p">,</span><span class="w">  </span><span class="c1">// NEW</span>
</span><span id="__span-7-8"><a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a><span class="w">    </span><span class="nb">None</span><span class="p">,</span>
</span><span id="__span-7-9"><a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a><span class="p">}</span>
</span><span id="__span-7-10"><a id="__codelineno-7-10" name="__codelineno-7-10" href="#__codelineno-7-10"></a>
</span><span id="__span-7-11"><a id="__codelineno-7-11" name="__codelineno-7-11" href="#__codelineno-7-11"></a><span class="k">impl</span><span class="w"> </span><span class="n">PyMLContext</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-7-12"><a id="__codelineno-7-12" name="__codelineno-7-12" href="#__codelineno-7-12"></a><span class="w">    </span><span class="k">fn</span><span class="w"> </span><span class="nf">select_backend</span><span class="p">(</span><span class="n">accelerated</span><span class="p">:</span><span class="w"> </span><span class="kt">bool</span><span class="p">,</span><span class="w"> </span><span class="n">power</span><span class="p">:</span><span class="w"> </span><span class="kp">&amp;</span><span class="kt">str</span><span class="p">)</span><span class="w"> </span><span class="p">-&gt;</span><span class="w"> </span><span class="p">(</span><span class="n">Backend</span><span class="p">,</span><span class="w"> </span><span class="kt">bool</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-7-13"><a id="__codelineno-7-13" name="__codelineno-7-13" href="#__codelineno-7-13"></a><span class="w">        </span><span class="c1">// TensorRT selection logic</span>
</span><span id="__span-7-14"><a id="__codelineno-7-14" name="__codelineno-7-14" href="#__codelineno-7-14"></a><span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">accelerated</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-7-15"><a id="__codelineno-7-15" name="__codelineno-7-15" href="#__codelineno-7-15"></a><span class="w">            </span><span class="cp">#[cfg(feature = </span><span class="s">&quot;tensorrt-runtime&quot;</span><span class="cp">)]</span>
</span><span id="__span-7-16"><a id="__codelineno-7-16" name="__codelineno-7-16" href="#__codelineno-7-16"></a><span class="w">            </span><span class="k">if</span><span class="w"> </span><span class="n">is_nvidia_gpu_available</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-7-17"><a id="__codelineno-7-17" name="__codelineno-7-17" href="#__codelineno-7-17"></a><span class="w">                </span><span class="c1">// Prefer TensorRT on NVIDIA GPUs for high-performance</span>
</span><span id="__span-7-18"><a id="__codelineno-7-18" name="__codelineno-7-18" href="#__codelineno-7-18"></a><span class="w">                </span><span class="k">if</span><span class="w"> </span><span class="n">power</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s">&quot;high-performance&quot;</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-7-19"><a id="__codelineno-7-19" name="__codelineno-7-19" href="#__codelineno-7-19"></a><span class="w">                    </span><span class="k">return</span><span class="w"> </span><span class="p">(</span><span class="n">Backend</span><span class="p">::</span><span class="n">TensorRT</span><span class="p">,</span><span class="w"> </span><span class="kc">true</span><span class="p">);</span>
</span><span id="__span-7-20"><a id="__codelineno-7-20" name="__codelineno-7-20" href="#__codelineno-7-20"></a><span class="w">                </span><span class="p">}</span>
</span><span id="__span-7-21"><a id="__codelineno-7-21" name="__codelineno-7-21" href="#__codelineno-7-21"></a><span class="w">            </span><span class="p">}</span>
</span><span id="__span-7-22"><a id="__codelineno-7-22" name="__codelineno-7-22" href="#__codelineno-7-22"></a><span class="w">        </span><span class="p">}</span>
</span><span id="__span-7-23"><a id="__codelineno-7-23" name="__codelineno-7-23" href="#__codelineno-7-23"></a>
</span><span id="__span-7-24"><a id="__codelineno-7-24" name="__codelineno-7-24" href="#__codelineno-7-24"></a><span class="w">        </span><span class="c1">// Existing logic for ONNX/CoreML/GGML...</span>
</span><span id="__span-7-25"><a id="__codelineno-7-25" name="__codelineno-7-25" href="#__codelineno-7-25"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-7-26"><a id="__codelineno-7-26" name="__codelineno-7-26" href="#__codelineno-7-26"></a>
</span><span id="__span-7-27"><a id="__codelineno-7-27" name="__codelineno-7-27" href="#__codelineno-7-27"></a><span class="w">    </span><span class="k">fn</span><span class="w"> </span><span class="nf">compute_tensorrt</span><span class="p">(</span>
</span><span id="__span-7-28"><a id="__codelineno-7-28" name="__codelineno-7-28" href="#__codelineno-7-28"></a><span class="w">        </span><span class="o">&amp;</span><span class="bp">self</span><span class="p">,</span>
</span><span id="__span-7-29"><a id="__codelineno-7-29" name="__codelineno-7-29" href="#__codelineno-7-29"></a><span class="w">        </span><span class="n">graph</span><span class="p">:</span><span class="w"> </span><span class="kp">&amp;</span><span class="nc">PyMLGraph</span><span class="p">,</span>
</span><span id="__span-7-30"><a id="__codelineno-7-30" name="__codelineno-7-30" href="#__codelineno-7-30"></a><span class="w">        </span><span class="n">inputs</span><span class="p">:</span><span class="w"> </span><span class="nc">HashMap</span><span class="o">&lt;</span><span class="nb">String</span><span class="p">,</span><span class="w"> </span><span class="n">Py</span><span class="o">&lt;</span><span class="n">PyArray</span><span class="o">&lt;</span><span class="kt">f32</span><span class="p">,</span><span class="w"> </span><span class="n">Dim</span><span class="o">&lt;</span><span class="n">IxDyn</span><span class="o">&gt;&gt;&gt;&gt;</span><span class="p">,</span>
</span><span id="__span-7-31"><a id="__codelineno-7-31" name="__codelineno-7-31" href="#__codelineno-7-31"></a><span class="w">    </span><span class="p">)</span><span class="w"> </span><span class="p">-&gt;</span><span class="w"> </span><span class="nb">Result</span><span class="o">&lt;</span><span class="n">HashMap</span><span class="o">&lt;</span><span class="nb">String</span><span class="p">,</span><span class="w"> </span><span class="n">Py</span><span class="o">&lt;</span><span class="n">PyArray</span><span class="o">&lt;</span><span class="kt">f32</span><span class="p">,</span><span class="w"> </span><span class="n">Dim</span><span class="o">&lt;</span><span class="n">IxDyn</span><span class="o">&gt;&gt;&gt;&gt;</span><span class="p">,</span><span class="w"> </span><span class="n">GraphError</span><span class="o">&gt;</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-7-32"><a id="__codelineno-7-32" name="__codelineno-7-32" href="#__codelineno-7-32"></a><span class="w">        </span><span class="cp">#[cfg(feature = </span><span class="s">&quot;tensorrt-runtime&quot;</span><span class="cp">)]</span>
</span><span id="__span-7-33"><a id="__codelineno-7-33" name="__codelineno-7-33" href="#__codelineno-7-33"></a><span class="w">        </span><span class="p">{</span>
</span><span id="__span-7-34"><a id="__codelineno-7-34" name="__codelineno-7-34" href="#__codelineno-7-34"></a><span class="w">            </span><span class="k">use</span><span class="w"> </span><span class="k">crate</span><span class="p">::</span><span class="n">converters</span><span class="p">::</span><span class="n">OnnxConverter</span><span class="p">;</span><span class="w">  </span><span class="c1">// Reuse ONNX converter!</span>
</span><span id="__span-7-35"><a id="__codelineno-7-35" name="__codelineno-7-35" href="#__codelineno-7-35"></a><span class="w">            </span><span class="k">use</span><span class="w"> </span><span class="k">crate</span><span class="p">::</span><span class="n">executors</span><span class="p">::</span><span class="n">tensorrt</span><span class="p">::{</span><span class="n">run_tensorrt_with_inputs</span><span class="p">,</span><span class="w"> </span><span class="n">TensorRTInput</span><span class="p">,</span><span class="w"> </span><span class="n">TensorRTPrecision</span><span class="p">};</span>
</span><span id="__span-7-36"><a id="__codelineno-7-36" name="__codelineno-7-36" href="#__codelineno-7-36"></a>
</span><span id="__span-7-37"><a id="__codelineno-7-37" name="__codelineno-7-37" href="#__codelineno-7-37"></a><span class="w">            </span><span class="c1">// 1. Convert GraphInfo to ONNX</span>
</span><span id="__span-7-38"><a id="__codelineno-7-38" name="__codelineno-7-38" href="#__codelineno-7-38"></a><span class="w">            </span><span class="kd">let</span><span class="w"> </span><span class="n">converter</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">OnnxConverter</span><span class="p">::</span><span class="n">default</span><span class="p">();</span>
</span><span id="__span-7-39"><a id="__codelineno-7-39" name="__codelineno-7-39" href="#__codelineno-7-39"></a><span class="w">            </span><span class="kd">let</span><span class="w"> </span><span class="n">converted</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">converter</span><span class="p">.</span><span class="n">convert</span><span class="p">(</span><span class="o">&amp;</span><span class="n">graph</span><span class="p">.</span><span class="n">graph</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
</span><span id="__span-7-40"><a id="__codelineno-7-40" name="__codelineno-7-40" href="#__codelineno-7-40"></a>
</span><span id="__span-7-41"><a id="__codelineno-7-41" name="__codelineno-7-41" href="#__codelineno-7-41"></a><span class="w">            </span><span class="c1">// 2. Convert inputs to TensorRTInput</span>
</span><span id="__span-7-42"><a id="__codelineno-7-42" name="__codelineno-7-42" href="#__codelineno-7-42"></a><span class="w">            </span><span class="kd">let</span><span class="w"> </span><span class="n">trt_inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">convert_numpy_to_tensorrt</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
</span><span id="__span-7-43"><a id="__codelineno-7-43" name="__codelineno-7-43" href="#__codelineno-7-43"></a>
</span><span id="__span-7-44"><a id="__codelineno-7-44" name="__codelineno-7-44" href="#__codelineno-7-44"></a><span class="w">            </span><span class="c1">// 3. Execute with TensorRT</span>
</span><span id="__span-7-45"><a id="__codelineno-7-45" name="__codelineno-7-45" href="#__codelineno-7-45"></a><span class="w">            </span><span class="kd">let</span><span class="w"> </span><span class="n">precision</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">TensorRTPrecision</span><span class="p">::</span><span class="n">FP16</span><span class="p">;</span><span class="w">  </span><span class="c1">// Could be configurable</span>
</span><span id="__span-7-46"><a id="__codelineno-7-46" name="__codelineno-7-46" href="#__codelineno-7-46"></a><span class="w">            </span><span class="kd">let</span><span class="w"> </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">run_tensorrt_with_inputs</span><span class="p">(</span><span class="o">&amp;</span><span class="n">converted</span><span class="p">.</span><span class="n">data</span><span class="p">,</span><span class="w"> </span><span class="n">trt_inputs</span><span class="p">,</span><span class="w"> </span><span class="n">precision</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
</span><span id="__span-7-47"><a id="__codelineno-7-47" name="__codelineno-7-47" href="#__codelineno-7-47"></a>
</span><span id="__span-7-48"><a id="__codelineno-7-48" name="__codelineno-7-48" href="#__codelineno-7-48"></a><span class="w">            </span><span class="c1">// 4. Convert outputs back to NumPy</span>
</span><span id="__span-7-49"><a id="__codelineno-7-49" name="__codelineno-7-49" href="#__codelineno-7-49"></a><span class="w">            </span><span class="n">convert_tensorrt_to_numpy</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
</span><span id="__span-7-50"><a id="__codelineno-7-50" name="__codelineno-7-50" href="#__codelineno-7-50"></a><span class="w">        </span><span class="p">}</span>
</span><span id="__span-7-51"><a id="__codelineno-7-51" name="__codelineno-7-51" href="#__codelineno-7-51"></a><span class="w">        </span><span class="cp">#[cfg(not(feature = </span><span class="s">&quot;tensorrt-runtime&quot;</span><span class="cp">))]</span>
</span><span id="__span-7-52"><a id="__codelineno-7-52" name="__codelineno-7-52" href="#__codelineno-7-52"></a><span class="w">        </span><span class="nb">Err</span><span class="p">(</span><span class="n">GraphError</span><span class="p">::</span><span class="n">BackendUnavailable</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-7-53"><a id="__codelineno-7-53" name="__codelineno-7-53" href="#__codelineno-7-53"></a><span class="w">            </span><span class="n">backend</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;TensorRT&quot;</span><span class="p">.</span><span class="n">to_string</span><span class="p">(),</span>
</span><span id="__span-7-54"><a id="__codelineno-7-54" name="__codelineno-7-54" href="#__codelineno-7-54"></a><span class="w">        </span><span class="p">})</span>
</span><span id="__span-7-55"><a id="__codelineno-7-55" name="__codelineno-7-55" href="#__codelineno-7-55"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-7-56"><a id="__codelineno-7-56" name="__codelineno-7-56" href="#__codelineno-7-56"></a><span class="p">}</span>
</span><span id="__span-7-57"><a id="__codelineno-7-57" name="__codelineno-7-57" href="#__codelineno-7-57"></a>
</span><span id="__span-7-58"><a id="__codelineno-7-58" name="__codelineno-7-58" href="#__codelineno-7-58"></a><span class="cp">#[cfg(feature = </span><span class="s">&quot;tensorrt-runtime&quot;</span><span class="cp">)]</span>
</span><span id="__span-7-59"><a id="__codelineno-7-59" name="__codelineno-7-59" href="#__codelineno-7-59"></a><span class="k">fn</span><span class="w"> </span><span class="nf">is_nvidia_gpu_available</span><span class="p">()</span><span class="w"> </span><span class="p">-&gt;</span><span class="w"> </span><span class="kt">bool</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-7-60"><a id="__codelineno-7-60" name="__codelineno-7-60" href="#__codelineno-7-60"></a><span class="w">    </span><span class="c1">// Check for CUDA-capable NVIDIA GPU</span>
</span><span id="__span-7-61"><a id="__codelineno-7-61" name="__codelineno-7-61" href="#__codelineno-7-61"></a><span class="w">    </span><span class="c1">// Could use cuda-runtime or parse nvidia-smi</span>
</span><span id="__span-7-62"><a id="__codelineno-7-62" name="__codelineno-7-62" href="#__codelineno-7-62"></a><span class="w">    </span><span class="n">std</span><span class="p">::</span><span class="n">process</span><span class="p">::</span><span class="n">Command</span><span class="p">::</span><span class="n">new</span><span class="p">(</span><span class="s">&quot;nvidia-smi&quot;</span><span class="p">)</span>
</span><span id="__span-7-63"><a id="__codelineno-7-63" name="__codelineno-7-63" href="#__codelineno-7-63"></a><span class="w">        </span><span class="p">.</span><span class="n">output</span><span class="p">()</span>
</span><span id="__span-7-64"><a id="__codelineno-7-64" name="__codelineno-7-64" href="#__codelineno-7-64"></a><span class="w">        </span><span class="p">.</span><span class="n">map</span><span class="p">(</span><span class="o">|</span><span class="n">output</span><span class="o">|</span><span class="w"> </span><span class="n">output</span><span class="p">.</span><span class="n">status</span><span class="p">.</span><span class="n">success</span><span class="p">())</span>
</span><span id="__span-7-65"><a id="__codelineno-7-65" name="__codelineno-7-65" href="#__codelineno-7-65"></a><span class="w">        </span><span class="p">.</span><span class="n">unwrap_or</span><span class="p">(</span><span class="kc">false</span><span class="p">)</span>
</span><span id="__span-7-66"><a id="__codelineno-7-66" name="__codelineno-7-66" href="#__codelineno-7-66"></a><span class="p">}</span>
</span></code></pre></div></p>
<h3 id="phase-5-engine-caching-performance-optimization">Phase 5: Engine Caching (Performance Optimization)<a class="headerlink" href="#phase-5-engine-caching-performance-optimization" title="Permanent link">&para;</a></h3>
<p><strong>Problem:</strong> TensorRT engine building can take 10-60 seconds on first run.</p>
<p><strong>Solution:</strong> Cache serialized engines to disk, keyed by model hash + GPU architecture.</p>
<p><strong>Implementation:</strong>
<div class="language-rust highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="k">use</span><span class="w"> </span><span class="n">std</span><span class="p">::</span><span class="n">path</span><span class="p">::</span><span class="n">PathBuf</span><span class="p">;</span>
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a><span class="k">use</span><span class="w"> </span><span class="n">std</span><span class="p">::</span><span class="n">fs</span><span class="p">;</span>
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a><span class="k">use</span><span class="w"> </span><span class="n">sha2</span><span class="p">::{</span><span class="n">Sha256</span><span class="p">,</span><span class="w"> </span><span class="n">Digest</span><span class="p">};</span>
</span><span id="__span-8-4"><a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a>
</span><span id="__span-8-5"><a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a><span class="k">fn</span><span class="w"> </span><span class="nf">get_engine_cache_path</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">:</span><span class="w"> </span><span class="kp">&amp;</span><span class="p">[</span><span class="kt">u8</span><span class="p">],</span><span class="w"> </span><span class="n">gpu_arch</span><span class="p">:</span><span class="w"> </span><span class="kp">&amp;</span><span class="kt">str</span><span class="p">,</span><span class="w"> </span><span class="n">precision</span><span class="p">:</span><span class="w"> </span><span class="nc">TensorRTPrecision</span><span class="p">)</span><span class="w"> </span><span class="p">-&gt;</span><span class="w"> </span><span class="nc">PathBuf</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-8-6"><a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="k">mut</span><span class="w"> </span><span class="n">hasher</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Sha256</span><span class="p">::</span><span class="n">new</span><span class="p">();</span>
</span><span id="__span-8-7"><a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a><span class="w">    </span><span class="n">hasher</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">);</span>
</span><span id="__span-8-8"><a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a><span class="w">    </span><span class="n">hasher</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="n">gpu_arch</span><span class="p">.</span><span class="n">as_bytes</span><span class="p">());</span>
</span><span id="__span-8-9"><a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a><span class="w">    </span><span class="n">hasher</span><span class="p">.</span><span class="n">update</span><span class="p">(</span><span class="fm">format!</span><span class="p">(</span><span class="s">&quot;{:?}&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">precision</span><span class="p">).</span><span class="n">as_bytes</span><span class="p">());</span>
</span><span id="__span-8-10"><a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">hash</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="fm">format!</span><span class="p">(</span><span class="s">&quot;{:x}&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">hasher</span><span class="p">.</span><span class="n">finalize</span><span class="p">());</span>
</span><span id="__span-8-11"><a id="__codelineno-8-11" name="__codelineno-8-11" href="#__codelineno-8-11"></a>
</span><span id="__span-8-12"><a id="__codelineno-8-12" name="__codelineno-8-12" href="#__codelineno-8-12"></a><span class="w">    </span><span class="n">PathBuf</span><span class="p">::</span><span class="n">from</span><span class="p">(</span><span class="fm">format!</span><span class="p">(</span><span class="s">&quot;.tensorrt_cache/engine_{}.trt&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">hash</span><span class="p">))</span>
</span><span id="__span-8-13"><a id="__codelineno-8-13" name="__codelineno-8-13" href="#__codelineno-8-13"></a><span class="p">}</span>
</span><span id="__span-8-14"><a id="__codelineno-8-14" name="__codelineno-8-14" href="#__codelineno-8-14"></a>
</span><span id="__span-8-15"><a id="__codelineno-8-15" name="__codelineno-8-15" href="#__codelineno-8-15"></a><span class="k">pub</span><span class="w"> </span><span class="k">fn</span><span class="w"> </span><span class="nf">run_tensorrt_with_caching</span><span class="p">(</span>
</span><span id="__span-8-16"><a id="__codelineno-8-16" name="__codelineno-8-16" href="#__codelineno-8-16"></a><span class="w">    </span><span class="n">onnx_model</span><span class="p">:</span><span class="w"> </span><span class="kp">&amp;</span><span class="p">[</span><span class="kt">u8</span><span class="p">],</span>
</span><span id="__span-8-17"><a id="__codelineno-8-17" name="__codelineno-8-17" href="#__codelineno-8-17"></a><span class="w">    </span><span class="n">inputs</span><span class="p">:</span><span class="w"> </span><span class="nc">HashMap</span><span class="o">&lt;</span><span class="nb">String</span><span class="p">,</span><span class="w"> </span><span class="n">TensorRTInput</span><span class="o">&gt;</span><span class="p">,</span>
</span><span id="__span-8-18"><a id="__codelineno-8-18" name="__codelineno-8-18" href="#__codelineno-8-18"></a><span class="w">    </span><span class="n">precision</span><span class="p">:</span><span class="w"> </span><span class="nc">TensorRTPrecision</span><span class="p">,</span>
</span><span id="__span-8-19"><a id="__codelineno-8-19" name="__codelineno-8-19" href="#__codelineno-8-19"></a><span class="p">)</span><span class="w"> </span><span class="p">-&gt;</span><span class="w"> </span><span class="nb">Result</span><span class="o">&lt;</span><span class="nb">Vec</span><span class="o">&lt;</span><span class="n">TensorRTOutput</span><span class="o">&gt;</span><span class="p">,</span><span class="w"> </span><span class="n">GraphError</span><span class="o">&gt;</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-8-20"><a id="__codelineno-8-20" name="__codelineno-8-20" href="#__codelineno-8-20"></a><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">gpu_arch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">get_gpu_architecture</span><span class="p">()</span><span class="o">?</span><span class="p">;</span><span class="w">  </span><span class="c1">// e.g., &quot;sm_89&quot; for RTX 4090</span>
</span><span id="__span-8-21"><a id="__codelineno-8-21" name="__codelineno-8-21" href="#__codelineno-8-21"></a><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">cache_path</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">get_engine_cache_path</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">,</span><span class="w"> </span><span class="o">&amp;</span><span class="n">gpu_arch</span><span class="p">,</span><span class="w"> </span><span class="n">precision</span><span class="p">);</span>
</span><span id="__span-8-22"><a id="__codelineno-8-22" name="__codelineno-8-22" href="#__codelineno-8-22"></a>
</span><span id="__span-8-23"><a id="__codelineno-8-23" name="__codelineno-8-23" href="#__codelineno-8-23"></a><span class="w">    </span><span class="kd">let</span><span class="w"> </span><span class="n">engine</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">cache_path</span><span class="p">.</span><span class="n">exists</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-8-24"><a id="__codelineno-8-24" name="__codelineno-8-24" href="#__codelineno-8-24"></a><span class="w">        </span><span class="c1">// Load cached engine</span>
</span><span id="__span-8-25"><a id="__codelineno-8-25" name="__codelineno-8-25" href="#__codelineno-8-25"></a><span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="n">serialized</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">fs</span><span class="p">::</span><span class="n">read</span><span class="p">(</span><span class="o">&amp;</span><span class="n">cache_path</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
</span><span id="__span-8-26"><a id="__codelineno-8-26" name="__codelineno-8-26" href="#__codelineno-8-26"></a><span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="n">runtime</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_infer_runtime</span><span class="p">(</span><span class="o">&amp;</span><span class="n">logger</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
</span><span id="__span-8-27"><a id="__codelineno-8-27" name="__codelineno-8-27" href="#__codelineno-8-27"></a><span class="w">        </span><span class="n">runtime</span><span class="p">.</span><span class="n">deserialize_cuda_engine</span><span class="p">(</span><span class="o">&amp;</span><span class="n">serialized</span><span class="p">)</span><span class="o">?</span>
</span><span id="__span-8-28"><a id="__codelineno-8-28" name="__codelineno-8-28" href="#__codelineno-8-28"></a><span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-8-29"><a id="__codelineno-8-29" name="__codelineno-8-29" href="#__codelineno-8-29"></a><span class="w">        </span><span class="c1">// Build new engine</span>
</span><span id="__span-8-30"><a id="__codelineno-8-30" name="__codelineno-8-30" href="#__codelineno-8-30"></a><span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="n">engine</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">build_engine</span><span class="p">(</span><span class="n">onnx_model</span><span class="p">,</span><span class="w"> </span><span class="n">precision</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
</span><span id="__span-8-31"><a id="__codelineno-8-31" name="__codelineno-8-31" href="#__codelineno-8-31"></a>
</span><span id="__span-8-32"><a id="__codelineno-8-32" name="__codelineno-8-32" href="#__codelineno-8-32"></a><span class="w">        </span><span class="c1">// Cache for future use</span>
</span><span id="__span-8-33"><a id="__codelineno-8-33" name="__codelineno-8-33" href="#__codelineno-8-33"></a><span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="n">serialized</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">engine</span><span class="p">.</span><span class="n">serialize</span><span class="p">()</span><span class="o">?</span><span class="p">;</span>
</span><span id="__span-8-34"><a id="__codelineno-8-34" name="__codelineno-8-34" href="#__codelineno-8-34"></a><span class="w">        </span><span class="n">fs</span><span class="p">::</span><span class="n">create_dir_all</span><span class="p">(</span><span class="n">cache_path</span><span class="p">.</span><span class="n">parent</span><span class="p">().</span><span class="n">unwrap</span><span class="p">())</span><span class="o">?</span><span class="p">;</span>
</span><span id="__span-8-35"><a id="__codelineno-8-35" name="__codelineno-8-35" href="#__codelineno-8-35"></a><span class="w">        </span><span class="n">fs</span><span class="p">::</span><span class="n">write</span><span class="p">(</span><span class="o">&amp;</span><span class="n">cache_path</span><span class="p">,</span><span class="w"> </span><span class="n">serialized</span><span class="p">)</span><span class="o">?</span><span class="p">;</span>
</span><span id="__span-8-36"><a id="__codelineno-8-36" name="__codelineno-8-36" href="#__codelineno-8-36"></a>
</span><span id="__span-8-37"><a id="__codelineno-8-37" name="__codelineno-8-37" href="#__codelineno-8-37"></a><span class="w">        </span><span class="n">engine</span>
</span><span id="__span-8-38"><a id="__codelineno-8-38" name="__codelineno-8-38" href="#__codelineno-8-38"></a><span class="w">    </span><span class="p">};</span>
</span><span id="__span-8-39"><a id="__codelineno-8-39" name="__codelineno-8-39" href="#__codelineno-8-39"></a>
</span><span id="__span-8-40"><a id="__codelineno-8-40" name="__codelineno-8-40" href="#__codelineno-8-40"></a><span class="w">    </span><span class="c1">// Execute with cached/new engine</span>
</span><span id="__span-8-41"><a id="__codelineno-8-41" name="__codelineno-8-41" href="#__codelineno-8-41"></a><span class="w">    </span><span class="n">execute_engine</span><span class="p">(</span><span class="n">engine</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">)</span>
</span><span id="__span-8-42"><a id="__codelineno-8-42" name="__codelineno-8-42" href="#__codelineno-8-42"></a><span class="p">}</span>
</span></code></pre></div></p>
<hr />
<h2 id="stats-operation-coverage-analysis">[STATS] Operation Coverage Analysis<a class="headerlink" href="#stats-operation-coverage-analysis" title="Permanent link">&para;</a></h2>
<h3 id="webnn-operations-tensorrt-support">WebNN Operations → TensorRT Support<a class="headerlink" href="#webnn-operations-tensorrt-support" title="Permanent link">&para;</a></h3>
<table>
<thead>
<tr>
<th>WebNN Operation</th>
<th>TensorRT Support</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Binary Ops</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>add</code>, <code>sub</code>, <code>mul</code>, <code>div</code></td>
<td>[OK] Full</td>
<td>Via Add, Sub, Mul, Div</td>
</tr>
<tr>
<td><code>matmul</code></td>
<td>[OK] Full</td>
<td>Via MatMul</td>
</tr>
<tr>
<td><code>pow</code></td>
<td>[OK] Full</td>
<td>Via Pow</td>
</tr>
<tr>
<td><strong>Activations</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>relu</code>, <code>sigmoid</code>, <code>tanh</code>, <code>softmax</code></td>
<td>[OK] Full</td>
<td>Native support</td>
</tr>
<tr>
<td><code>gelu</code>, <code>elu</code>, <code>leakyRelu</code>, <code>prelu</code></td>
<td>[OK] Full</td>
<td>Native support</td>
</tr>
<tr>
<td><code>hardSigmoid</code>, <code>hardSwish</code>, <code>softplus</code>, <code>softsign</code></td>
<td>[OK] Full</td>
<td>Native support</td>
</tr>
<tr>
<td><strong>Convolution</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>conv2d</code>, <code>convTranspose2d</code></td>
<td>[OK] Full</td>
<td>2D and 3D supported</td>
</tr>
<tr>
<td><strong>Pooling</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>averagePool2d</code>, <code>maxPool2d</code></td>
<td>[OK] Full</td>
<td>2D/3D, indices unsupported for MaxPool</td>
</tr>
<tr>
<td><code>globalAveragePool</code>, <code>globalMaxPool</code></td>
<td>[OK] Full</td>
<td>Native support</td>
</tr>
<tr>
<td><strong>Normalization</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>batchNormalization</code></td>
<td>[OK] Full</td>
<td>Native support</td>
</tr>
<tr>
<td><code>instanceNormalization</code></td>
<td>[OK] Full</td>
<td>Native support</td>
</tr>
<tr>
<td><code>layerNormalization</code></td>
<td>[OK] Full</td>
<td>Native support</td>
</tr>
<tr>
<td><strong>Reduction</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>All <code>reduce*</code> operations</td>
<td>[OK] Full</td>
<td>10 reduction ops supported</td>
</tr>
<tr>
<td><strong>Tensor Ops</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>reshape</code>, <code>transpose</code>, <code>concat</code>, <code>split</code></td>
<td>[OK] Full</td>
<td>Native support</td>
</tr>
<tr>
<td><code>slice</code>, <code>gather</code>, <code>scatter</code>, <code>pad</code>, <code>tile</code></td>
<td>[OK] Full</td>
<td>Native support</td>
</tr>
<tr>
<td><code>squeeze</code>, <code>unsqueeze</code>, <code>expand</code></td>
<td>[OK] Full</td>
<td>Native support</td>
</tr>
<tr>
<td><strong>Logic</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>All comparison and logical ops</td>
<td>[OK] Full</td>
<td>9 ops supported</td>
</tr>
<tr>
<td><strong>Math</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>All element-wise math</td>
<td>[OK] Full</td>
<td>23 ops supported</td>
</tr>
<tr>
<td><strong>Quantization</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>quantizeLinear</code>, <code>dequantizeLinear</code></td>
<td>[OK] Full</td>
<td>Native support</td>
</tr>
<tr>
<td><strong>Advanced</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>argMax</code>, <code>argMin</code></td>
<td>[OK] Full</td>
<td>Via ArgMax, ArgMin</td>
</tr>
<tr>
<td><code>cast</code>, <code>clamp</code>, <code>where</code></td>
<td>[OK] Full</td>
<td>Via Cast, Clip, Where</td>
</tr>
<tr>
<td><code>gemm</code></td>
<td>[OK] Full</td>
<td>Via Gemm</td>
</tr>
</tbody>
</table>
<p><strong>Coverage:</strong> ~95%+ of WebNN spec (TensorRT has 300+ ONNX ops, WebNN has 85-95 ops)</p>
<p><strong>Not Supported:</strong>
- Some RNN/LSTM restrictions (bidirectional requires matching activations)
- MaxPool indices output
- Certain dilation/padding combinations
- DOUBLE precision (cast to FLOAT32)</p>
<hr />
<h2 id="challenges-solutions">Challenges &amp; Solutions<a class="headerlink" href="#challenges-solutions" title="Permanent link">&para;</a></h2>
<h3 id="challenge-1-rust-bindings-maturity">Challenge 1: Rust Bindings Maturity<a class="headerlink" href="#challenge-1-rust-bindings-maturity" title="Permanent link">&para;</a></h3>
<p><strong>Problem:</strong> Existing Rust bindings (<code>tensorrt-rs</code>) are outdated (TensorRT 5-7, last update 2020).</p>
<p><strong>Solutions:</strong>
1. <strong>Use <code>easy-tensorrt-sys</code></strong>: Newer fork with better CUDA integration via <code>cudarc</code>
2. <strong>Create custom FFI</strong>: Use <code>bindgen</code> to generate fresh bindings for TensorRT 10.x
3. <strong>Fork and update <code>tensorrt-rs</code></strong>: Modernize existing crate for TensorRT 10.x
4. <strong>Wait for official bindings</strong>: NVIDIA may release official Rust support (unlikely short-term)</p>
<p><strong>Recommendation:</strong> Create custom FFI bindings for TensorRT 10.x C++ API using <code>bindgen</code>. Focus on core interfaces: IBuilder, INetworkDefinition, IExecutionContext, IParser.</p>
<h3 id="challenge-2-cuda-dependency">Challenge 2: CUDA Dependency<a class="headerlink" href="#challenge-2-cuda-dependency" title="Permanent link">&para;</a></h3>
<p><strong>Problem:</strong> TensorRT requires CUDA toolkit and NVIDIA GPU runtime.</p>
<p><strong>Solutions:</strong>
- <strong>Feature flag</strong>: Only enable with <code>tensorrt-runtime</code> feature
- <strong>Runtime detection</strong>: Check for NVIDIA GPU before selecting backend
- <strong>Clear errors</strong>: Provide helpful error if CUDA unavailable
- <strong>Documentation</strong>: Document CUDA installation requirements</p>
<h3 id="challenge-3-engine-build-time">Challenge 3: Engine Build Time<a class="headerlink" href="#challenge-3-engine-build-time" title="Permanent link">&para;</a></h3>
<p><strong>Problem:</strong> Building TensorRT engine can take 10-60 seconds on first run.</p>
<p><strong>Solutions:</strong>
- <strong>Engine caching</strong>: Serialize engines to disk, key by model hash + GPU arch
- <strong>Ahead-of-time compilation</strong>: Pre-build engines for target GPUs
- <strong>JIT progress</strong>: Show progress during engine building
- <strong>TensorRT for RTX</strong>: JIT compilation in &lt;30 seconds (Windows 11)</p>
<h3 id="challenge-4-precision-selection">Challenge 4: Precision Selection<a class="headerlink" href="#challenge-4-precision-selection" title="Permanent link">&para;</a></h3>
<p><strong>Problem:</strong> TensorRT supports FP32, FP16, INT8, FP8, FP4. How to select?</p>
<p><strong>Solutions:</strong>
- Follow WebNN device hints:
  - <code>power="high-performance"</code> → FP16 (2x faster than FP32)
  - <code>power="default"</code> → FP16
  - <code>power="low-power"</code> → INT8 (requires calibration)
- Add optional precision parameter to <code>compute()</code>
- Auto-detect GPU capability (e.g., FP8 only on Ada/Hopper)</p>
<h3 id="challenge-5-platform-support">Challenge 5: Platform Support<a class="headerlink" href="#challenge-5-platform-support" title="Permanent link">&para;</a></h3>
<p><strong>Problem:</strong> TensorRT is NVIDIA GPU-only (Linux, Windows). No macOS/AMD support.</p>
<p><strong>Solutions:</strong>
- <strong>Runtime detection</strong>: Check for NVIDIA GPU at context creation
- <strong>Graceful fallback</strong>: Fall back to ONNX Runtime if TensorRT unavailable
- <strong>Clear documentation</strong>: Document platform requirements
- <strong>Windows focus</strong>: Leverage TensorRT for RTX (Windows 11 + RTX GPUs)</p>
<h3 id="challenge-6-dynamic-shapes">Challenge 6: Dynamic Shapes<a class="headerlink" href="#challenge-6-dynamic-shapes" title="Permanent link">&para;</a></h3>
<p><strong>Problem:</strong> TensorRT engines can have fixed or dynamic input shapes.</p>
<p><strong>Solutions:</strong>
- <strong>Use explicit batch</strong>: Set <code>ExplicitBatchDimensions</code> flag
- <strong>Optimization profiles</strong>: Define min/opt/max shapes for dynamic inputs
- <strong>Runtime binding</strong>: Bind shapes at execution time
- <strong>Future work</strong>: Add dynamic shape support incrementally</p>
<hr />
<h2 id="target-implementation-roadmap">[TARGET] Implementation Roadmap<a class="headerlink" href="#target-implementation-roadmap" title="Permanent link">&para;</a></h2>
<h3 id="phase-1-proof-of-concept-2-3-days">Phase 1: Proof of Concept (2-3 days)<a class="headerlink" href="#phase-1-proof-of-concept-2-3-days" title="Permanent link">&para;</a></h3>
<ul>
<li>[ ] Research TensorRT C++ API and identify core interfaces needed</li>
<li>[ ] Create minimal FFI bindings using <code>bindgen</code> for TensorRT 10.x</li>
<li>[ ] Implement basic executor for ONNX → TensorRT → inference</li>
<li>[ ] Test with simple operation (add, matmul) on NVIDIA GPU</li>
<li>[ ] Validate FP32 precision works correctly</li>
</ul>
<h3 id="phase-2-core-functionality-5-7-days">Phase 2: Core Functionality (5-7 days)<a class="headerlink" href="#phase-2-core-functionality-5-7-days" title="Permanent link">&para;</a></h3>
<ul>
<li>[ ] Expand FFI bindings for full IBuilder/INetworkDefinition API</li>
<li>[ ] Implement ONNX parser integration</li>
<li>[ ] Add FP16/INT8 precision support</li>
<li>[ ] Implement GPU memory management (CUDA buffers)</li>
<li>[ ] Add error handling and validation</li>
<li>[ ] Test with 20+ WebNN operations</li>
</ul>
<h3 id="phase-3-performance-optimization-3-5-days">Phase 3: Performance Optimization (3-5 days)<a class="headerlink" href="#phase-3-performance-optimization-3-5-days" title="Permanent link">&para;</a></h3>
<ul>
<li>[ ] Implement engine caching to disk</li>
<li>[ ] Add engine serialization/deserialization</li>
<li>[ ] Optimize memory allocation/deallocation</li>
<li>[ ] Add batch size optimization</li>
<li>[ ] Profile and benchmark vs ONNX Runtime</li>
</ul>
<h3 id="phase-4-python-integration-2-3-days">Phase 4: Python Integration (2-3 days)<a class="headerlink" href="#phase-4-python-integration-2-3-days" title="Permanent link">&para;</a></h3>
<ul>
<li>[ ] Add Backend::TensorRT to context selection</li>
<li>[ ] Implement <code>compute_tensorrt()</code> method</li>
<li>[ ] Add NVIDIA GPU detection</li>
<li>[ ] Add device selection logic (prefer TensorRT on NVIDIA)</li>
<li>[ ] Test with Python API examples</li>
</ul>
<h3 id="phase-5-documentation-testing-2-3-days">Phase 5: Documentation &amp; Testing (2-3 days)<a class="headerlink" href="#phase-5-documentation-testing-2-3-days" title="Permanent link">&para;</a></h3>
<ul>
<li>[ ] Update docs/implementation-status.md with TensorRT coverage</li>
<li>[ ] Update docs/architecture.md with TensorRT backend</li>
<li>[ ] Create example: <code>examples/tensorrt_inference.py</code></li>
<li>[ ] Add comprehensive unit tests (Rust + Python)</li>
<li>[ ] Document CUDA installation requirements</li>
<li>[ ] Update README.md with TensorRT backend section</li>
</ul>
<h3 id="phase-6-advanced-features-future">Phase 6: Advanced Features (Future)<a class="headerlink" href="#phase-6-advanced-features-future" title="Permanent link">&para;</a></h3>
<ul>
<li>[ ] TensorRT for RTX support (Windows 11)</li>
<li>[ ] INT8 calibration for quantization</li>
<li>[ ] Dynamic shape support</li>
<li>[ ] Multi-stream execution</li>
<li>[ ] DLA (Deep Learning Accelerator) support</li>
<li>[ ] TensorRT-LLM integration for transformer models</li>
</ul>
<p><strong>Total Estimated Time:</strong> 14-21 days for phases 1-5</p>
<hr />
<h2 id="testing-strategy">Testing Strategy<a class="headerlink" href="#testing-strategy" title="Permanent link">&para;</a></h2>
<h3 id="unit-tests-rust">Unit Tests (Rust)<a class="headerlink" href="#unit-tests-rust" title="Permanent link">&para;</a></h3>
<p><strong>File:</strong> <code>src/executors/tensorrt.rs</code>
<div class="language-rust highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="cp">#[cfg(all(test, feature = </span><span class="s">&quot;tensorrt-runtime&quot;</span><span class="cp">))]</span>
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a><span class="k">mod</span><span class="w"> </span><span class="nn">tests</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-9-3"><a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a><span class="w">    </span><span class="k">use</span><span class="w"> </span><span class="k">super</span><span class="p">::</span><span class="o">*</span><span class="p">;</span>
</span><span id="__span-9-4"><a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a>
</span><span id="__span-9-5"><a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a><span class="w">    </span><span class="cp">#[test]</span>
</span><span id="__span-9-6"><a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a><span class="w">    </span><span class="k">fn</span><span class="w"> </span><span class="nf">builds_engine_from_onnx</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-9-7"><a id="__codelineno-9-7" name="__codelineno-9-7" href="#__codelineno-9-7"></a><span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="n">onnx_model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_simple_add_onnx</span><span class="p">();</span>
</span><span id="__span-9-8"><a id="__codelineno-9-8" name="__codelineno-9-8" href="#__codelineno-9-8"></a><span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="n">logger</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_logger</span><span class="p">();</span>
</span><span id="__span-9-9"><a id="__codelineno-9-9" name="__codelineno-9-9" href="#__codelineno-9-9"></a><span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="n">builder</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_infer_builder</span><span class="p">(</span><span class="o">&amp;</span><span class="n">logger</span><span class="p">).</span><span class="n">unwrap</span><span class="p">();</span>
</span><span id="__span-9-10"><a id="__codelineno-9-10" name="__codelineno-9-10" href="#__codelineno-9-10"></a><span class="w">        </span><span class="fm">assert!</span><span class="p">(</span><span class="n">builder</span><span class="p">.</span><span class="n">is_valid</span><span class="p">());</span>
</span><span id="__span-9-11"><a id="__codelineno-9-11" name="__codelineno-9-11" href="#__codelineno-9-11"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-9-12"><a id="__codelineno-9-12" name="__codelineno-9-12" href="#__codelineno-9-12"></a>
</span><span id="__span-9-13"><a id="__codelineno-9-13" name="__codelineno-9-13" href="#__codelineno-9-13"></a><span class="w">    </span><span class="cp">#[test]</span>
</span><span id="__span-9-14"><a id="__codelineno-9-14" name="__codelineno-9-14" href="#__codelineno-9-14"></a><span class="w">    </span><span class="k">fn</span><span class="w"> </span><span class="nf">executes_add_operation</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-9-15"><a id="__codelineno-9-15" name="__codelineno-9-15" href="#__codelineno-9-15"></a><span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="o">!</span><span class="n">is_nvidia_gpu_available</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-9-16"><a id="__codelineno-9-16" name="__codelineno-9-16" href="#__codelineno-9-16"></a><span class="w">            </span><span class="fm">eprintln!</span><span class="p">(</span><span class="s">&quot;Skipping test: No NVIDIA GPU available&quot;</span><span class="p">);</span>
</span><span id="__span-9-17"><a id="__codelineno-9-17" name="__codelineno-9-17" href="#__codelineno-9-17"></a><span class="w">            </span><span class="k">return</span><span class="p">;</span>
</span><span id="__span-9-18"><a id="__codelineno-9-18" name="__codelineno-9-18" href="#__codelineno-9-18"></a><span class="w">        </span><span class="p">}</span>
</span><span id="__span-9-19"><a id="__codelineno-9-19" name="__codelineno-9-19" href="#__codelineno-9-19"></a>
</span><span id="__span-9-20"><a id="__codelineno-9-20" name="__codelineno-9-20" href="#__codelineno-9-20"></a><span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="n">onnx_model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_simple_add_onnx</span><span class="p">();</span>
</span><span id="__span-9-21"><a id="__codelineno-9-21" name="__codelineno-9-21" href="#__codelineno-9-21"></a><span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="n">inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">create_test_inputs</span><span class="p">();</span>
</span><span id="__span-9-22"><a id="__codelineno-9-22" name="__codelineno-9-22" href="#__codelineno-9-22"></a><span class="w">        </span><span class="kd">let</span><span class="w"> </span><span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">run_tensorrt_with_inputs</span><span class="p">(</span><span class="o">&amp;</span><span class="n">onnx_model</span><span class="p">,</span><span class="w"> </span><span class="n">inputs</span><span class="p">,</span><span class="w"> </span><span class="n">TensorRTPrecision</span><span class="p">::</span><span class="n">FP32</span><span class="p">).</span><span class="n">unwrap</span><span class="p">();</span>
</span><span id="__span-9-23"><a id="__codelineno-9-23" name="__codelineno-9-23" href="#__codelineno-9-23"></a>
</span><span id="__span-9-24"><a id="__codelineno-9-24" name="__codelineno-9-24" href="#__codelineno-9-24"></a><span class="w">        </span><span class="fm">assert_eq!</span><span class="p">(</span><span class="n">outputs</span><span class="p">.</span><span class="n">len</span><span class="p">(),</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
</span><span id="__span-9-25"><a id="__codelineno-9-25" name="__codelineno-9-25" href="#__codelineno-9-25"></a><span class="w">        </span><span class="fm">assert_eq!</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">shape</span><span class="p">,</span><span class="w"> </span><span class="fm">vec!</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">]);</span>
</span><span id="__span-9-26"><a id="__codelineno-9-26" name="__codelineno-9-26" href="#__codelineno-9-26"></a><span class="w">        </span><span class="c1">// Verify output values</span>
</span><span id="__span-9-27"><a id="__codelineno-9-27" name="__codelineno-9-27" href="#__codelineno-9-27"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-9-28"><a id="__codelineno-9-28" name="__codelineno-9-28" href="#__codelineno-9-28"></a>
</span><span id="__span-9-29"><a id="__codelineno-9-29" name="__codelineno-9-29" href="#__codelineno-9-29"></a><span class="w">    </span><span class="cp">#[test]</span>
</span><span id="__span-9-30"><a id="__codelineno-9-30" name="__codelineno-9-30" href="#__codelineno-9-30"></a><span class="w">    </span><span class="k">fn</span><span class="w"> </span><span class="nf">fp16_precision_works</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-9-31"><a id="__codelineno-9-31" name="__codelineno-9-31" href="#__codelineno-9-31"></a><span class="w">        </span><span class="c1">// Test FP16 execution</span>
</span><span id="__span-9-32"><a id="__codelineno-9-32" name="__codelineno-9-32" href="#__codelineno-9-32"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-9-33"><a id="__codelineno-9-33" name="__codelineno-9-33" href="#__codelineno-9-33"></a>
</span><span id="__span-9-34"><a id="__codelineno-9-34" name="__codelineno-9-34" href="#__codelineno-9-34"></a><span class="w">    </span><span class="cp">#[test]</span>
</span><span id="__span-9-35"><a id="__codelineno-9-35" name="__codelineno-9-35" href="#__codelineno-9-35"></a><span class="w">    </span><span class="k">fn</span><span class="w"> </span><span class="nf">engine_caching_works</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
</span><span id="__span-9-36"><a id="__codelineno-9-36" name="__codelineno-9-36" href="#__codelineno-9-36"></a><span class="w">        </span><span class="c1">// Test cache hit/miss</span>
</span><span id="__span-9-37"><a id="__codelineno-9-37" name="__codelineno-9-37" href="#__codelineno-9-37"></a><span class="w">    </span><span class="p">}</span>
</span><span id="__span-9-38"><a id="__codelineno-9-38" name="__codelineno-9-38" href="#__codelineno-9-38"></a><span class="p">}</span>
</span></code></pre></div></p>
<h3 id="python-tests">Python Tests<a class="headerlink" href="#python-tests" title="Permanent link">&para;</a></h3>
<p><strong>File:</strong> <code>tests/test_tensorrt_backend.py</code>
<div class="language-python highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">pytest</span>
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">webnn</span>
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</span><span id="__span-10-4"><a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a><span class="kn">import</span><span class="w"> </span><span class="nn">subprocess</span>
</span><span id="__span-10-5"><a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a>
</span><span id="__span-10-6"><a id="__codelineno-10-6" name="__codelineno-10-6" href="#__codelineno-10-6"></a><span class="k">def</span><span class="w"> </span><span class="nf">has_nvidia_gpu</span><span class="p">():</span>
</span><span id="__span-10-7"><a id="__codelineno-10-7" name="__codelineno-10-7" href="#__codelineno-10-7"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Check if NVIDIA GPU is available&quot;&quot;&quot;</span>
</span><span id="__span-10-8"><a id="__codelineno-10-8" name="__codelineno-10-8" href="#__codelineno-10-8"></a>    <span class="k">try</span><span class="p">:</span>
</span><span id="__span-10-9"><a id="__codelineno-10-9" name="__codelineno-10-9" href="#__codelineno-10-9"></a>        <span class="n">result</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="s2">&quot;nvidia-smi&quot;</span><span class="p">],</span> <span class="n">capture_output</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-10-10"><a id="__codelineno-10-10" name="__codelineno-10-10" href="#__codelineno-10-10"></a>        <span class="k">return</span> <span class="n">result</span><span class="o">.</span><span class="n">returncode</span> <span class="o">==</span> <span class="mi">0</span>
</span><span id="__span-10-11"><a id="__codelineno-10-11" name="__codelineno-10-11" href="#__codelineno-10-11"></a>    <span class="k">except</span> <span class="ne">FileNotFoundError</span><span class="p">:</span>
</span><span id="__span-10-12"><a id="__codelineno-10-12" name="__codelineno-10-12" href="#__codelineno-10-12"></a>        <span class="k">return</span> <span class="kc">False</span>
</span><span id="__span-10-13"><a id="__codelineno-10-13" name="__codelineno-10-13" href="#__codelineno-10-13"></a>
</span><span id="__span-10-14"><a id="__codelineno-10-14" name="__codelineno-10-14" href="#__codelineno-10-14"></a><span class="k">def</span><span class="w"> </span><span class="nf">has_tensorrt_runtime</span><span class="p">():</span>
</span><span id="__span-10-15"><a id="__codelineno-10-15" name="__codelineno-10-15" href="#__codelineno-10-15"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Check if TensorRT runtime is available&quot;&quot;&quot;</span>
</span><span id="__span-10-16"><a id="__codelineno-10-16" name="__codelineno-10-16" href="#__codelineno-10-16"></a>    <span class="k">try</span><span class="p">:</span>
</span><span id="__span-10-17"><a id="__codelineno-10-17" name="__codelineno-10-17" href="#__codelineno-10-17"></a>        <span class="kn">import</span><span class="w"> </span><span class="nn">webnn._rustnn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">rustnn</span>
</span><span id="__span-10-18"><a id="__codelineno-10-18" name="__codelineno-10-18" href="#__codelineno-10-18"></a>        <span class="k">return</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">rustnn</span><span class="p">,</span> <span class="s1">&#39;tensorrt_available&#39;</span><span class="p">)</span>
</span><span id="__span-10-19"><a id="__codelineno-10-19" name="__codelineno-10-19" href="#__codelineno-10-19"></a>    <span class="k">except</span><span class="p">:</span>
</span><span id="__span-10-20"><a id="__codelineno-10-20" name="__codelineno-10-20" href="#__codelineno-10-20"></a>        <span class="k">return</span> <span class="kc">False</span>
</span><span id="__span-10-21"><a id="__codelineno-10-21" name="__codelineno-10-21" href="#__codelineno-10-21"></a>
</span><span id="__span-10-22"><a id="__codelineno-10-22" name="__codelineno-10-22" href="#__codelineno-10-22"></a><span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">skipif</span><span class="p">(</span><span class="ow">not</span> <span class="n">has_nvidia_gpu</span><span class="p">(),</span> <span class="n">reason</span><span class="o">=</span><span class="s2">&quot;No NVIDIA GPU available&quot;</span><span class="p">)</span>
</span><span id="__span-10-23"><a id="__codelineno-10-23" name="__codelineno-10-23" href="#__codelineno-10-23"></a><span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">skipif</span><span class="p">(</span><span class="ow">not</span> <span class="n">has_tensorrt_runtime</span><span class="p">(),</span> <span class="n">reason</span><span class="o">=</span><span class="s2">&quot;TensorRT runtime not available&quot;</span><span class="p">)</span>
</span><span id="__span-10-24"><a id="__codelineno-10-24" name="__codelineno-10-24" href="#__codelineno-10-24"></a><span class="k">def</span><span class="w"> </span><span class="nf">test_tensorrt_add</span><span class="p">():</span>
</span><span id="__span-10-25"><a id="__codelineno-10-25" name="__codelineno-10-25" href="#__codelineno-10-25"></a>    <span class="n">ml</span> <span class="o">=</span> <span class="n">webnn</span><span class="o">.</span><span class="n">ML</span><span class="p">()</span>
</span><span id="__span-10-26"><a id="__codelineno-10-26" name="__codelineno-10-26" href="#__codelineno-10-26"></a>    <span class="n">context</span> <span class="o">=</span> <span class="n">ml</span><span class="o">.</span><span class="n">create_context</span><span class="p">(</span><span class="n">accelerated</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">power_preference</span><span class="o">=</span><span class="s2">&quot;high-performance&quot;</span><span class="p">)</span>
</span><span id="__span-10-27"><a id="__codelineno-10-27" name="__codelineno-10-27" href="#__codelineno-10-27"></a>
</span><span id="__span-10-28"><a id="__codelineno-10-28" name="__codelineno-10-28" href="#__codelineno-10-28"></a>    <span class="c1"># Should select TensorRT on NVIDIA GPU</span>
</span><span id="__span-10-29"><a id="__codelineno-10-29" name="__codelineno-10-29" href="#__codelineno-10-29"></a>    <span class="k">assert</span> <span class="n">context</span><span class="o">.</span><span class="n">backend</span> <span class="o">==</span> <span class="s2">&quot;tensorrt&quot;</span>
</span><span id="__span-10-30"><a id="__codelineno-10-30" name="__codelineno-10-30" href="#__codelineno-10-30"></a>
</span><span id="__span-10-31"><a id="__codelineno-10-31" name="__codelineno-10-31" href="#__codelineno-10-31"></a>    <span class="n">builder</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">create_graph_builder</span><span class="p">()</span>
</span><span id="__span-10-32"><a id="__codelineno-10-32" name="__codelineno-10-32" href="#__codelineno-10-32"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">input</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="s2">&quot;float32&quot;</span><span class="p">)</span>
</span><span id="__span-10-33"><a id="__codelineno-10-33" name="__codelineno-10-33" href="#__codelineno-10-33"></a>    <span class="n">y</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">input</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="s2">&quot;float32&quot;</span><span class="p">)</span>
</span><span id="__span-10-34"><a id="__codelineno-10-34" name="__codelineno-10-34" href="#__codelineno-10-34"></a>    <span class="n">z</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</span><span id="__span-10-35"><a id="__codelineno-10-35" name="__codelineno-10-35" href="#__codelineno-10-35"></a>
</span><span id="__span-10-36"><a id="__codelineno-10-36" name="__codelineno-10-36" href="#__codelineno-10-36"></a>    <span class="n">graph</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">build</span><span class="p">({</span><span class="s2">&quot;output&quot;</span><span class="p">:</span> <span class="n">z</span><span class="p">})</span>
</span><span id="__span-10-37"><a id="__codelineno-10-37" name="__codelineno-10-37" href="#__codelineno-10-37"></a>
</span><span id="__span-10-38"><a id="__codelineno-10-38" name="__codelineno-10-38" href="#__codelineno-10-38"></a>    <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="__span-10-39"><a id="__codelineno-10-39" name="__codelineno-10-39" href="#__codelineno-10-39"></a>        <span class="s2">&quot;x&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
</span><span id="__span-10-40"><a id="__codelineno-10-40" name="__codelineno-10-40" href="#__codelineno-10-40"></a>        <span class="s2">&quot;y&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
</span><span id="__span-10-41"><a id="__codelineno-10-41" name="__codelineno-10-41" href="#__codelineno-10-41"></a>    <span class="p">}</span>
</span><span id="__span-10-42"><a id="__codelineno-10-42" name="__codelineno-10-42" href="#__codelineno-10-42"></a>
</span><span id="__span-10-43"><a id="__codelineno-10-43" name="__codelineno-10-43" href="#__codelineno-10-43"></a>    <span class="n">outputs</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
</span><span id="__span-10-44"><a id="__codelineno-10-44" name="__codelineno-10-44" href="#__codelineno-10-44"></a>    <span class="n">expected</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="__span-10-45"><a id="__codelineno-10-45" name="__codelineno-10-45" href="#__codelineno-10-45"></a>    <span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">],</span> <span class="n">expected</span><span class="p">)</span>
</span><span id="__span-10-46"><a id="__codelineno-10-46" name="__codelineno-10-46" href="#__codelineno-10-46"></a>
</span><span id="__span-10-47"><a id="__codelineno-10-47" name="__codelineno-10-47" href="#__codelineno-10-47"></a><span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">skipif</span><span class="p">(</span><span class="ow">not</span> <span class="n">has_nvidia_gpu</span><span class="p">(),</span> <span class="n">reason</span><span class="o">=</span><span class="s2">&quot;No NVIDIA GPU available&quot;</span><span class="p">)</span>
</span><span id="__span-10-48"><a id="__codelineno-10-48" name="__codelineno-10-48" href="#__codelineno-10-48"></a><span class="k">def</span><span class="w"> </span><span class="nf">test_tensorrt_fp16_precision</span><span class="p">():</span>
</span><span id="__span-10-49"><a id="__codelineno-10-49" name="__codelineno-10-49" href="#__codelineno-10-49"></a>    <span class="c1"># Test FP16 execution</span>
</span><span id="__span-10-50"><a id="__codelineno-10-50" name="__codelineno-10-50" href="#__codelineno-10-50"></a>    <span class="k">pass</span>
</span><span id="__span-10-51"><a id="__codelineno-10-51" name="__codelineno-10-51" href="#__codelineno-10-51"></a>
</span><span id="__span-10-52"><a id="__codelineno-10-52" name="__codelineno-10-52" href="#__codelineno-10-52"></a><span class="nd">@pytest</span><span class="o">.</span><span class="n">mark</span><span class="o">.</span><span class="n">skipif</span><span class="p">(</span><span class="ow">not</span> <span class="n">has_nvidia_gpu</span><span class="p">(),</span> <span class="n">reason</span><span class="o">=</span><span class="s2">&quot;No NVIDIA GPU available&quot;</span><span class="p">)</span>
</span><span id="__span-10-53"><a id="__codelineno-10-53" name="__codelineno-10-53" href="#__codelineno-10-53"></a><span class="k">def</span><span class="w"> </span><span class="nf">test_tensorrt_mobilenet</span><span class="p">():</span>
</span><span id="__span-10-54"><a id="__codelineno-10-54" name="__codelineno-10-54" href="#__codelineno-10-54"></a>    <span class="c1"># Test full MobileNetV2 model on TensorRT</span>
</span><span id="__span-10-55"><a id="__codelineno-10-55" name="__codelineno-10-55" href="#__codelineno-10-55"></a>    <span class="k">pass</span>
</span></code></pre></div></p>
<h3 id="performance-benchmarks">Performance Benchmarks<a class="headerlink" href="#performance-benchmarks" title="Permanent link">&para;</a></h3>
<p><strong>File:</strong> <code>benchmarks/tensorrt_vs_onnx.py</code>
<div class="language-python highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="kn">import</span><span class="w"> </span><span class="nn">time</span>
</span><span id="__span-11-2"><a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a><span class="kn">import</span><span class="w"> </span><span class="nn">webnn</span>
</span><span id="__span-11-3"><a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
</span><span id="__span-11-4"><a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a>
</span><span id="__span-11-5"><a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a><span class="k">def</span><span class="w"> </span><span class="nf">benchmark_backend</span><span class="p">(</span><span class="n">backend_name</span><span class="p">,</span> <span class="n">accelerated</span><span class="p">,</span> <span class="n">power_preference</span><span class="p">):</span>
</span><span id="__span-11-6"><a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a>    <span class="n">ml</span> <span class="o">=</span> <span class="n">webnn</span><span class="o">.</span><span class="n">ML</span><span class="p">()</span>
</span><span id="__span-11-7"><a id="__codelineno-11-7" name="__codelineno-11-7" href="#__codelineno-11-7"></a>    <span class="n">context</span> <span class="o">=</span> <span class="n">ml</span><span class="o">.</span><span class="n">create_context</span><span class="p">(</span><span class="n">accelerated</span><span class="o">=</span><span class="n">accelerated</span><span class="p">,</span> <span class="n">power_preference</span><span class="o">=</span><span class="n">power_preference</span><span class="p">)</span>
</span><span id="__span-11-8"><a id="__codelineno-11-8" name="__codelineno-11-8" href="#__codelineno-11-8"></a>
</span><span id="__span-11-9"><a id="__codelineno-11-9" name="__codelineno-11-9" href="#__codelineno-11-9"></a>    <span class="c1"># Build MobileNetV2 graph</span>
</span><span id="__span-11-10"><a id="__codelineno-11-10" name="__codelineno-11-10" href="#__codelineno-11-10"></a>    <span class="n">graph</span> <span class="o">=</span> <span class="n">build_mobilenetv2</span><span class="p">(</span><span class="n">context</span><span class="p">)</span>
</span><span id="__span-11-11"><a id="__codelineno-11-11" name="__codelineno-11-11" href="#__codelineno-11-11"></a>
</span><span id="__span-11-12"><a id="__codelineno-11-12" name="__codelineno-11-12" href="#__codelineno-11-12"></a>    <span class="c1"># Warmup</span>
</span><span id="__span-11-13"><a id="__codelineno-11-13" name="__codelineno-11-13" href="#__codelineno-11-13"></a>    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
</span><span id="__span-11-14"><a id="__codelineno-11-14" name="__codelineno-11-14" href="#__codelineno-11-14"></a>        <span class="n">context</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
</span><span id="__span-11-15"><a id="__codelineno-11-15" name="__codelineno-11-15" href="#__codelineno-11-15"></a>
</span><span id="__span-11-16"><a id="__codelineno-11-16" name="__codelineno-11-16" href="#__codelineno-11-16"></a>    <span class="c1"># Benchmark</span>
</span><span id="__span-11-17"><a id="__codelineno-11-17" name="__codelineno-11-17" href="#__codelineno-11-17"></a>    <span class="n">times</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-11-18"><a id="__codelineno-11-18" name="__codelineno-11-18" href="#__codelineno-11-18"></a>    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
</span><span id="__span-11-19"><a id="__codelineno-11-19" name="__codelineno-11-19" href="#__codelineno-11-19"></a>        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
</span><span id="__span-11-20"><a id="__codelineno-11-20" name="__codelineno-11-20" href="#__codelineno-11-20"></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="n">context</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
</span><span id="__span-11-21"><a id="__codelineno-11-21" name="__codelineno-11-21" href="#__codelineno-11-21"></a>        <span class="n">times</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
</span><span id="__span-11-22"><a id="__codelineno-11-22" name="__codelineno-11-22" href="#__codelineno-11-22"></a>
</span><span id="__span-11-23"><a id="__codelineno-11-23" name="__codelineno-11-23" href="#__codelineno-11-23"></a>    <span class="k">return</span> <span class="p">{</span>
</span><span id="__span-11-24"><a id="__codelineno-11-24" name="__codelineno-11-24" href="#__codelineno-11-24"></a>        <span class="s2">&quot;backend&quot;</span><span class="p">:</span> <span class="n">backend_name</span><span class="p">,</span>
</span><span id="__span-11-25"><a id="__codelineno-11-25" name="__codelineno-11-25" href="#__codelineno-11-25"></a>        <span class="s2">&quot;mean_ms&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">times</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">,</span>
</span><span id="__span-11-26"><a id="__codelineno-11-26" name="__codelineno-11-26" href="#__codelineno-11-26"></a>        <span class="s2">&quot;std_ms&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">times</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">,</span>
</span><span id="__span-11-27"><a id="__codelineno-11-27" name="__codelineno-11-27" href="#__codelineno-11-27"></a>        <span class="s2">&quot;min_ms&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">times</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">,</span>
</span><span id="__span-11-28"><a id="__codelineno-11-28" name="__codelineno-11-28" href="#__codelineno-11-28"></a>        <span class="s2">&quot;max_ms&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">times</span><span class="p">)</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">,</span>
</span><span id="__span-11-29"><a id="__codelineno-11-29" name="__codelineno-11-29" href="#__codelineno-11-29"></a>    <span class="p">}</span>
</span><span id="__span-11-30"><a id="__codelineno-11-30" name="__codelineno-11-30" href="#__codelineno-11-30"></a>
</span><span id="__span-11-31"><a id="__codelineno-11-31" name="__codelineno-11-31" href="#__codelineno-11-31"></a><span class="c1"># Compare backends</span>
</span><span id="__span-11-32"><a id="__codelineno-11-32" name="__codelineno-11-32" href="#__codelineno-11-32"></a><span class="n">onnx_gpu</span> <span class="o">=</span> <span class="n">benchmark_backend</span><span class="p">(</span><span class="s2">&quot;ONNX GPU&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;high-performance&quot;</span><span class="p">)</span>
</span><span id="__span-11-33"><a id="__codelineno-11-33" name="__codelineno-11-33" href="#__codelineno-11-33"></a><span class="n">tensorrt</span> <span class="o">=</span> <span class="n">benchmark_backend</span><span class="p">(</span><span class="s2">&quot;TensorRT&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="s2">&quot;high-performance&quot;</span><span class="p">)</span>
</span><span id="__span-11-34"><a id="__codelineno-11-34" name="__codelineno-11-34" href="#__codelineno-11-34"></a>
</span><span id="__span-11-35"><a id="__codelineno-11-35" name="__codelineno-11-35" href="#__codelineno-11-35"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ONNX GPU: </span><span class="si">{</span><span class="n">onnx_gpu</span><span class="p">[</span><span class="s1">&#39;mean_ms&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">ms ± </span><span class="si">{</span><span class="n">onnx_gpu</span><span class="p">[</span><span class="s1">&#39;std_ms&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">ms&quot;</span><span class="p">)</span>
</span><span id="__span-11-36"><a id="__codelineno-11-36" name="__codelineno-11-36" href="#__codelineno-11-36"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;TensorRT: </span><span class="si">{</span><span class="n">tensorrt</span><span class="p">[</span><span class="s1">&#39;mean_ms&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">ms ± </span><span class="si">{</span><span class="n">tensorrt</span><span class="p">[</span><span class="s1">&#39;std_ms&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">ms&quot;</span><span class="p">)</span>
</span><span id="__span-11-37"><a id="__codelineno-11-37" name="__codelineno-11-37" href="#__codelineno-11-37"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Speedup: </span><span class="si">{</span><span class="n">onnx_gpu</span><span class="p">[</span><span class="s1">&#39;mean_ms&#39;</span><span class="p">]</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">tensorrt</span><span class="p">[</span><span class="s1">&#39;mean_ms&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">x&quot;</span><span class="p">)</span>
</span></code></pre></div></p>
<h3 id="makefile-targets">Makefile Targets<a class="headerlink" href="#makefile-targets" title="Permanent link">&para;</a></h3>
<div class="language-makefile highlight"><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="c"># Add to Makefile</span>
</span><span id="__span-12-2"><a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a><span class="nf">.PHONY</span><span class="o">:</span><span class="w"> </span><span class="n">tensorrt</span>-<span class="n">dev</span>
</span><span id="__span-12-3"><a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a><span class="nf">tensorrt-dev</span><span class="o">:</span>
</span><span id="__span-12-4"><a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a><span class="w">    </span>maturin<span class="w"> </span>develop<span class="w"> </span>--features<span class="w"> </span>python,tensorrt-runtime
</span><span id="__span-12-5"><a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a>
</span><span id="__span-12-6"><a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a><span class="nf">.PHONY</span><span class="o">:</span><span class="w"> </span><span class="n">test</span>-<span class="n">tensorrt</span>
</span><span id="__span-12-7"><a id="__codelineno-12-7" name="__codelineno-12-7" href="#__codelineno-12-7"></a><span class="nf">test-tensorrt</span><span class="o">:</span>
</span><span id="__span-12-8"><a id="__codelineno-12-8" name="__codelineno-12-8" href="#__codelineno-12-8"></a><span class="w">    </span>cargo<span class="w"> </span><span class="nb">test</span><span class="w"> </span>--features<span class="w"> </span>tensorrt-runtime
</span><span id="__span-12-9"><a id="__codelineno-12-9" name="__codelineno-12-9" href="#__codelineno-12-9"></a><span class="w">    </span>pytest<span class="w"> </span>tests/test_tensorrt_backend.py<span class="w"> </span>-v
</span><span id="__span-12-10"><a id="__codelineno-12-10" name="__codelineno-12-10" href="#__codelineno-12-10"></a>
</span><span id="__span-12-11"><a id="__codelineno-12-11" name="__codelineno-12-11" href="#__codelineno-12-11"></a><span class="nf">.PHONY</span><span class="o">:</span><span class="w"> </span><span class="n">benchmark</span>-<span class="n">tensorrt</span>
</span><span id="__span-12-12"><a id="__codelineno-12-12" name="__codelineno-12-12" href="#__codelineno-12-12"></a><span class="nf">benchmark-tensorrt</span><span class="o">:</span>
</span><span id="__span-12-13"><a id="__codelineno-12-13" name="__codelineno-12-13" href="#__codelineno-12-13"></a><span class="w">    </span>python<span class="w"> </span>benchmarks/tensorrt_vs_onnx.py
</span></code></pre></div>
<hr />
<h2 id="references">References<a class="headerlink" href="#references" title="Permanent link">&para;</a></h2>
<h3 id="tensorrt-resources">TensorRT Resources<a class="headerlink" href="#tensorrt-resources" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="https://docs.nvidia.com/deeplearning/tensorrt/latest/index.html">TensorRT Documentation</a></li>
<li><a href="https://developer.nvidia.com/tensorrt">TensorRT SDK</a></li>
<li><a href="https://docs.nvidia.com/deeplearning/tensorrt/latest/architecture/architecture-overview.html">TensorRT Architecture Overview</a></li>
<li><a href="https://docs.nvidia.com/deeplearning/tensorrt-rtx/latest/index.html">TensorRT for RTX (Windows 11)</a></li>
<li><a href="https://developer.nvidia.com/blog/nvidia-tensorrt-for-rtx-introduces-an-optimized-inference-ai-library-on-windows/">TensorRT for RTX Announcement</a></li>
<li><a href="https://developer.nvidia.com/blog/run-high-performance-ai-applications-with-nvidia-tensorrt-for-rtx/">Run High-Performance AI with TensorRT for RTX</a></li>
</ul>
<h3 id="onnx-tensorrt">ONNX-TensorRT<a class="headerlink" href="#onnx-tensorrt" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="https://github.com/onnx/onnx-tensorrt">ONNX-TensorRT GitHub</a></li>
<li><a href="https://github.com/onnx/onnx-tensorrt/blob/main/docs/operators.md">Supported ONNX Operators</a></li>
<li><a href="https://docs.nvidia.com/deeplearning/tensorrt/latest/getting-started/support-matrix.html">TensorRT Support Matrix</a></li>
</ul>
<h3 id="rust-bindings">Rust Bindings<a class="headerlink" href="#rust-bindings" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="https://github.com/mstallmo/tensorrt-rs">tensorrt-rs (GitHub)</a></li>
<li><a href="https://crates.io/crates/tensorrt-rs">tensorrt-rs (crates.io)</a></li>
<li><a href="https://crates.io/crates/easy-tensorrt-sys">easy-tensorrt-sys (crates.io)</a></li>
<li><a href="https://lib.rs/crates/tensorrt-sys">TensorRT-sys</a></li>
</ul>
<h3 id="webnn-spec">WebNN Spec<a class="headerlink" href="#webnn-spec" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="https://www.w3.org/TR/webnn/">W3C WebNN API Specification</a></li>
<li><a href="https://github.com/webmachinelearning/webnn/blob/main/device-selection-explainer.md">WebNN Device Selection Explainer</a></li>
</ul>
<h3 id="related-projects">Related Projects<a class="headerlink" href="#related-projects" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="https://github.com/NVIDIA/TensorRT-LLM">TensorRT-LLM</a></li>
<li><a href="https://github.com/triton-inference-server/server">NVIDIA Triton Inference Server</a></li>
<li><a href="https://github.com/pytorch/TensorRT">Torch-TensorRT</a></li>
</ul>
<hr />
<h2 id="summary">Summary<a class="headerlink" href="#summary" title="Permanent link">&para;</a></h2>
<p><strong>TensorRT Integration Value:</strong>
- [OK] <strong>Best GPU performance</strong> on NVIDIA hardware (RTX, A100, H100)
- [OK] <strong>Advanced quantization</strong> (FP16, INT8, FP8, FP4)
- [OK] <strong>Production-ready</strong> (widely deployed in NVIDIA ecosystem)
- [OK] <strong>ONNX-native</strong> (reuse existing ONNX converter)
- [OK] <strong>95%+ operation coverage</strong> (300+ ONNX ops)
- [OK] <strong>TensorRT for RTX</strong> (optimized for Windows 11 + RTX GPUs)</p>
<p><strong>Key Design Decisions:</strong>
1. <strong>Reuse ONNX converter</strong> (no new converter needed!)
2. <strong>Custom FFI bindings</strong> for TensorRT 10.x C++ API
3. <strong>Engine caching</strong> to avoid rebuild overhead
4. <strong>FP16 default</strong> for 2x speedup over FP32
5. <strong>Prefer TensorRT</strong> on NVIDIA GPUs with <code>accelerated=True</code> + <code>power="high-performance"</code>
6. <strong>Graceful fallback</strong> to ONNX Runtime if TensorRT unavailable</p>
<p><strong>Platform Support:</strong>
- <strong>Primary</strong>: Linux + NVIDIA GPU (CUDA)
- <strong>Secondary</strong>: Windows 11 + NVIDIA RTX GPU (TensorRT for RTX)
- <strong>Not supported</strong>: macOS (no NVIDIA GPU), AMD GPUs</p>
<p><strong>Next Steps:</strong>
1. Create FFI bindings for TensorRT 10.x
2. Implement basic executor with FP32 support
3. Add FP16/INT8 precision modes
4. Implement engine caching
5. Integrate with Python API
6. Benchmark vs ONNX Runtime GPU</p>
<hr />
<p><strong>Status:</strong> Planning document (not yet implemented)</p>
<p><strong>Estimated Effort:</strong> 14-21 days for full integration with caching and FP16/INT8 support</p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2024 Your Organization
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/your-org/rustnn" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://pypi.org/project/webnn/" target="_blank" rel="noopener" title="pypi.org" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6M286.2 444.7a20.4 20.4 0 1 1 0-40.7 20.4 20.4 0 1 1 0 40.7M167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4m-6.6-183.4a20.4 20.4 0 1 1 0 40.8 20.4 20.4 0 1 1 0-40.8"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      
      <script id="__config" type="application/json">{"annotate": null, "base": "..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.sections", "navigation.expand", "navigation.top", "search.suggest", "search.highlight", "content.tabs.link", "content.code.annotation", "content.code.copy"], "search": "../assets/javascripts/workers/search.7a47a382.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../assets/javascripts/bundle.e71a0d61.min.js"></script>
      
    
  </body>
</html>